{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfm.gibbs import MyFMOrderedProbit\n",
    "from typing import List, Dict, Union\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "import myfm\n",
    "from myfm import RelationBlock, MyFMOrderedProbit, MyFMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from myfm.utils.benchmark_data import MovieLens10MDataManager\n",
    "from myfm.utils.callbacks.libfm import (\n",
    "    LibFMLikeCallbackBase,\n",
    "    OrderedProbitCallback,\n",
    "    RegressionCallback,\n",
    ")\n",
    "from myfm.utils.encoders import CategoryValueToSparseEncoder\n",
    "from scipy import sparse as sps\n",
    "\n",
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.fold_index = 9\n",
    "        self.algorithm = 'regression'\n",
    "        self.iteration = 512\n",
    "        self.dimension = 128\n",
    "        self.stricter_protocol = True\n",
    "        self.feature = 'svdpp'\n",
    "\n",
    "args = Args()\n",
    "\n",
    "\"\"\"\n",
    "parser.add_argument(\n",
    "    \"fold_index\",\n",
    "    type=int,\n",
    "    help=\"which index set to use as a test within 10-fold CV.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-a\",\n",
    "    \"--algorithm\",\n",
    "    type=str,\n",
    "    choices=[\"regression\", \"oprobit\"],\n",
    "    default=\"regression\",\n",
    "    help=\"specify the output type.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-i\", \"--iteration\", type=int, help=\"mcmc iteration\", default=512\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-d\",\n",
    "    \"--dimension\",\n",
    "    type=int,\n",
    "    help=\"fm embedding dimension\",\n",
    "    default=128,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stricter_protocol\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use the \\\"stricter\\\" protocol (i.e., don't include the test set implicit information) stated in [Rendle, '19].\",\n",
    "    default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-f\",\n",
    "    \"--feature\",\n",
    "    type=str,\n",
    "    choices=[\"mf\", \"svdpp\", \"timesvd\", \"timesvdpp\", \"timesvdpp_flipped\"],\n",
    "    help=\"feature set used in the experiment.\",\n",
    "    default=\"timesvdpp_flipped\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# Additional features.\n",
    "# We add\n",
    "# 1. date of evaluation as categorical variables\n",
    "# 2. \"all users who have evaluated a movie in the train set\" or\n",
    "# 3. \"all movies rated by a user\" as a feature of user/movie.\n",
    "if args.feature == \"mf\":\n",
    "    use_date = False\n",
    "    use_iu = False\n",
    "    use_ii = False\n",
    "elif args.feature == \"svdpp\":\n",
    "    use_date = False\n",
    "    use_iu = True\n",
    "    use_ii = False\n",
    "elif args.feature == \"timesvd\":\n",
    "    use_date = True\n",
    "    use_iu = False\n",
    "    use_ii = False\n",
    "elif args.feature == \"timesvdpp\":\n",
    "    use_date = True\n",
    "    use_iu = True\n",
    "    use_ii = False\n",
    "elif args.feature == \"timesvdpp_flipped\":\n",
    "    use_date = True  # use date info or not\n",
    "    use_iu = True  # use implicit user feature\n",
    "    use_ii = True  # use implicit item feature\n",
    "else:\n",
    "    raise ValueError(\"unknown feature set specified.\")\n",
    "\n",
    "FOLD_INDEX = args.fold_index\n",
    "ITERATION = args.iteration\n",
    "DIMENSION = args.dimension\n",
    "if FOLD_INDEX < 0 or FOLD_INDEX >= 10:\n",
    "    raise ValueError(\"fold_index must be in the range(10).\")\n",
    "ALGORITHM = args.algorithm\n",
    "# # data_manager = MovieLens10MDataManager()\n",
    "# df_train, df_test = data_manager.load_rating_kfold_split(\n",
    "#     10, FOLD_INDEX, random_seed\n",
    "# )\n",
    "\n",
    "data_pd = pd.read_csv('/Users/arda/Desktop/cil/data/data_train.csv')\n",
    "data_pd[\"user_id\"] = data_pd[\"Id\"].apply(lambda x: int(x.split(\"_\")[0].split(\"r\")[-1])).values\n",
    "data_pd[\"movie_id\"] = data_pd[\"Id\"].apply(lambda x: int(x.split(\"_\")[1].split(\"c\")[-1])).values\n",
    "data_pd[\"rating\"] = data_pd[\"Prediction\"].values\n",
    "data_pd = data_pd[[\"user_id\", \"movie_id\", \"rating\"]]\n",
    "\n",
    "df_train, df_test = train_test_split(data_pd, train_size=0.9, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape = (1059256, 3), df_test.shape = (117696, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha=1.7372, rmse_mean=0.9758, rmse_this=1.1392, rmse_all_but_5=0.9760: 100%|██████████| 512/512 [1:37:00<00:00, 11.37s/it]\n"
     ]
    }
   ],
   "source": [
    "if ALGORITHM == \"oprobit\":\n",
    "    # interpret the rating 0.5, 1.0 ... , 5.0 as class (0, 1, ... , 10)\n",
    "    for df_ in [df_train, df_test]:\n",
    "        df_[\"rating\"] -= 0.5\n",
    "        df_[\"rating\"] *= 2\n",
    "        df_[\"rating\"] = df_.rating.astype(np.int32)\n",
    "\n",
    "if args.stricter_protocol:\n",
    "    implicit_data_source = df_train\n",
    "else:\n",
    "    implicit_data_source = pd.concat([df_train, df_test])\n",
    "\n",
    "user_to_internal = CategoryValueToSparseEncoder[int](\n",
    "    implicit_data_source.user_id.values\n",
    ")\n",
    "movie_to_internal = CategoryValueToSparseEncoder[int](\n",
    "    implicit_data_source.movie_id.values\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"df_train.shape = {}, df_test.shape = {}\".format(df_train.shape, df_test.shape)\n",
    ")\n",
    "# treat the days of events as categorical variable\n",
    "# date_encoder = CategoryValueToSparseEncoder[pd.Timestamp](\n",
    "#     implicit_data_source.timestamp.dt.date.values\n",
    "# )\n",
    "\n",
    "# def categorize_date(df):\n",
    "#     return date_encoder.to_sparse(df.timestamp.dt.date.values)\n",
    "\n",
    "movie_vs_watched: Dict[int, List[int]] = dict()\n",
    "user_vs_watched: Dict[int, List[int]] = dict()\n",
    "\n",
    "for row in implicit_data_source.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)\n",
    "\n",
    "if use_date:\n",
    "    X_date_train = categorize_date(df_train)\n",
    "    X_date_test = categorize_date(df_test)\n",
    "else:\n",
    "    X_date_train, X_date_test = (None, None)\n",
    "\n",
    "# setup grouping\n",
    "feature_group_sizes = []\n",
    "if use_date:\n",
    "    feature_group_sizes.append(\n",
    "        len(date_encoder),  # date\n",
    "    )\n",
    "\n",
    "feature_group_sizes.append(len(user_to_internal))  # user ids\n",
    "\n",
    "if use_iu:\n",
    "    # all movies which a user watched\n",
    "    feature_group_sizes.append(len(movie_to_internal))\n",
    "\n",
    "feature_group_sizes.append(len(movie_to_internal))  # movie ids\n",
    "\n",
    "if use_ii:\n",
    "    feature_group_sizes.append(\n",
    "        len(user_to_internal)  # all the users who watched a movies\n",
    "    )\n",
    "\n",
    "grouping = [i for i, size in enumerate(feature_group_sizes) for _ in range(size)]\n",
    "\n",
    "def augment_user_id(user_ids: List[int]) -> sps.csr_matrix:\n",
    "    X = user_to_internal.to_sparse(user_ids)\n",
    "    if not use_iu:\n",
    "        return X\n",
    "    data: List[float] = []\n",
    "    row: List[int] = []\n",
    "    col: List[int] = []\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        watched_movies = user_vs_watched.get(user_id, [])\n",
    "        normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "        for mid in watched_movies:\n",
    "            data.append(normalizer)\n",
    "            col.append(movie_to_internal[mid])\n",
    "            row.append(index)\n",
    "    return sps.hstack(\n",
    "        [\n",
    "            X,\n",
    "            sps.csr_matrix(\n",
    "                (data, (row, col)),\n",
    "                shape=(len(user_ids), len(movie_to_internal)),\n",
    "            ),\n",
    "        ],\n",
    "        format=\"csr\",\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids: List[int]):\n",
    "    X = movie_to_internal.to_sparse(movie_ids)\n",
    "    if not use_ii:\n",
    "        return X\n",
    "\n",
    "    data: List[float] = []\n",
    "    row: List[int] = []\n",
    "    col: List[int] = []\n",
    "\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        watched_users = movie_vs_watched.get(movie_id, [])\n",
    "        normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "        for uid in watched_users:\n",
    "            data.append(normalizer)\n",
    "            row.append(index)\n",
    "            col.append(user_to_internal[uid])\n",
    "    return sps.hstack(\n",
    "        [\n",
    "            X,\n",
    "            sps.csr_matrix(\n",
    "                (data, (row, col)),\n",
    "                shape=(len(movie_ids), len(user_to_internal)),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Create RelationBlock.\n",
    "train_blocks: List[RelationBlock] = []\n",
    "test_blocks: List[RelationBlock] = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.user_id, return_inverse=True)\n",
    "    target.append(RelationBlock(user_map, augment_user_id(unique_users)))\n",
    "    unique_movies, movie_map = np.unique(source.movie_id, return_inverse=True)\n",
    "    target.append(RelationBlock(movie_map, augment_movie_id(unique_movies)))\n",
    "\n",
    "trace_path = \"rmse_{0}_fold_{1}.csv\".format(ALGORITHM, FOLD_INDEX)\n",
    "\n",
    "callback: LibFMLikeCallbackBase\n",
    "fm: Union[MyFMRegressor, MyFMOrderedProbit]\n",
    "if ALGORITHM == \"regression\":\n",
    "    fm = myfm.MyFMRegressor(rank=DIMENSION)\n",
    "    callback = RegressionCallback(\n",
    "        ITERATION,\n",
    "        X_date_test,\n",
    "        df_test.rating.values,\n",
    "        X_rel_test=test_blocks,\n",
    "        clip_min=0.5,\n",
    "        clip_max=5.0,\n",
    "        trace_path=trace_path,\n",
    "    )\n",
    "else:\n",
    "    fm = myfm.MyFMOrderedProbit(rank=DIMENSION)\n",
    "    callback = OrderedProbitCallback(\n",
    "        ITERATION,\n",
    "        X_date_test,\n",
    "        df_test.rating.values,\n",
    "        n_class=10,\n",
    "        X_rel_test=test_blocks,\n",
    "        trace_path=trace_path,\n",
    "    )\n",
    "fm.fit(\n",
    "    X_date_train,\n",
    "    df_train.rating.values,\n",
    "    X_rel=train_blocks,\n",
    "    grouping=grouping,\n",
    "    n_iter=callback.n_iter,\n",
    "    callback=callback,\n",
    "    n_kept_samples=1,\n",
    ")\n",
    "with open(\n",
    "    \"callback_result_{0}_fold_{1}.pkl\".format(ALGORITHM, FOLD_INDEX), \"wb\"\n",
    ") as ofs:\n",
    "    pickle.dump(callback, ofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
