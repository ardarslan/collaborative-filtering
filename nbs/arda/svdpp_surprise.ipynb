{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 20\n",
      " processing epoch 21\n",
      " processing epoch 22\n",
      " processing epoch 23\n",
      " processing epoch 24\n",
      " processing epoch 25\n",
      " processing epoch 26\n",
      " processing epoch 27\n",
      " processing epoch 28\n",
      " processing epoch 29\n",
      " processing epoch 30\n",
      " processing epoch 31\n",
      " processing epoch 32\n",
      " processing epoch 33\n",
      " processing epoch 34\n",
      " processing epoch 35\n",
      " processing epoch 36\n",
      " processing epoch 37\n",
      " processing epoch 38\n",
      " processing epoch 39\n",
      " processing epoch 40\n",
      " processing epoch 41\n",
      " processing epoch 42\n",
      " processing epoch 43\n",
      " processing epoch 44\n",
      " processing epoch 45\n",
      " processing epoch 46\n",
      " processing epoch 47\n",
      " processing epoch 48\n",
      " processing epoch 49\n",
      " processing epoch 50\n",
      " processing epoch 51\n",
      " processing epoch 52\n",
      " processing epoch 53\n",
      " processing epoch 54\n",
      " processing epoch 55\n",
      " processing epoch 56\n",
      " processing epoch 57\n",
      " processing epoch 58\n",
      " processing epoch 59\n",
      " processing epoch 60\n",
      " processing epoch 61\n",
      " processing epoch 62\n",
      " processing epoch 63\n",
      " processing epoch 64\n",
      " processing epoch 65\n",
      " processing epoch 66\n",
      " processing epoch 67\n",
      " processing epoch 68\n",
      " processing epoch 69\n",
      " processing epoch 70\n",
      " processing epoch 71\n",
      " processing epoch 72\n",
      " processing epoch 73\n",
      " processing epoch 74\n",
      " processing epoch 75\n",
      " processing epoch 76\n",
      " processing epoch 77\n",
      " processing epoch 78\n",
      " processing epoch 79\n",
      " processing epoch 80\n",
      " processing epoch 81\n",
      " processing epoch 82\n",
      " processing epoch 83\n",
      " processing epoch 84\n",
      "RMSE: 1.0780\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise import AlgoBase, PredictionImpossible, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVDpp\n",
    "\n",
    "all_df = pd.read_csv(\"../../data/data_train.csv\")\n",
    "all_df['user_id'] = all_df['Id'].apply(lambda x: int(x.split(\"_\")[0].split(\"r\")[-1]))\n",
    "all_df['movie_id'] = all_df['Id'].apply(lambda x: int(x.split(\"_\")[-1].split(\"c\")[-1]))\n",
    "all_df['rating'] = all_df['Prediction'].values\n",
    "all_df = all_df[['user_id', 'movie_id', 'rating']]\n",
    "number_of_users = all_df.user_id.unique().shape[0]\n",
    "number_of_movies = all_df.movie_id.unique().shape[0]\n",
    "\n",
    "# train_df, test_df = train_test_split(all_df, test_size=0.1, random_state=42)\n",
    "\n",
    "reader = Reader()\n",
    "dataset = Dataset.load_from_df(all_df, reader)\n",
    "\n",
    "trainset, testset = train_test_split(dataset, test_size=0.10)\n",
    "\n",
    "model = SVDpp(verbose=True, n_factors=192, n_epochs=85)\n",
    "\n",
    "# fit the model to the training set\n",
    "model.fit(trainset)\n",
    "\n",
    "# compute the predictions\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# compute the RMSE on the testset\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "# data = np.full((number_of_users, number_of_movies), np.mean(train_df.rating.values))\n",
    "# mask = np.zeros((number_of_users, number_of_movies))\n",
    "# for user_id, movie_id, rating in zip(train_df.user_id.tolist(), train_df.movie_id.tolist(), train_df.rating.tolist()):\n",
    "#     data[user_id - 1][movie_id - 1] = rating\n",
    "#     mask[user_id - 1][movie_id - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0779551864562102"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prediction_from_full_matrix(reconstructed_matrix):\n",
    "    predictions = np.zeros(test_df.shape[0])\n",
    "    for i, (user_id, movie_id) in enumerate(zip(test_df.user_id.tolist(), test_df.movie_id.tolist())):\n",
    "        predictions[i] = reconstructed_matrix[user_id - 1][movie_id - 1]\n",
    "    return predictions\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using SVD is: 1.0657\n"
     ]
    }
   ],
   "source": [
    "k_singular_values = 10\n",
    "number_of_singular_values = min(number_of_users, number_of_movies)\n",
    "\n",
    "U, s, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "\n",
    "S = np.zeros((number_of_movies, number_of_movies))\n",
    "S[:k_singular_values, :k_singular_values] = np.diag(s[:k_singular_values])\n",
    "\n",
    "reconstructed_matrix = U.dot(S).dot(Vt)\n",
    "\n",
    "predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "\n",
    "print(\"RMSE using SVD is: {:.4f}\".format(rmse(test_df.rating.values, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#@title Use GPU in colab: Runtime->Change Runtime type\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_dim = 10000\n",
    "        self.item_dim = 1000\n",
    "        \n",
    "        self.layer_1 = nn.Linear(1000, 100)\n",
    "        self.layer_1a = nn.Linear(100, 100)\n",
    "        \n",
    "        # self.vae = nn.Linear(100, 100)\n",
    "        \n",
    "        # self.layer_3 = nn.Linear(50, 100)\n",
    "        self.cls_layer = nn.Linear(100, 1000)\n",
    "\n",
    "    def forward(self, data):\n",
    "        net_data = data\n",
    "\n",
    "        # Encoder layers\n",
    "        net_data = F.relu(self.layer_1(net_data))\n",
    "        net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        net_data = F.relu(self.layer_1a(net_data))\n",
    "        net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        # VAE bottleneck\n",
    "        # vae = self.vae(net_data)\n",
    "        # mus_q, log_sigmas_q = torch.split(vae, 50, dim=-1)\n",
    "        # stds_q = torch.exp(0.5 * log_sigmas_q)\n",
    "        \n",
    "        # KL = 0.5 * (-log_sigmas_q + torch.exp(log_sigmas_q) + mus_q ** 2 - 1)\n",
    "        # KL = torch.sum(KL, dim=-1)\n",
    "        # KL = torch.mean(KL)\n",
    "        \n",
    "        # Sample random value if training,\n",
    "        # use the mean during evaluation\n",
    "        # if not self.training:\n",
    "        #     sampled_z = mus_q\n",
    "        # else:\n",
    "        #     eps = torch.randn(stds_q.shape, dtype=torch.float, device=device)\n",
    "        #     sampled_z = mus_q + eps * stds_q\n",
    "        \n",
    "        # Decoder layers\n",
    "        # net_data = F.relu(self.layer_3(sampled_z))\n",
    "        # net_data = F.dropout(net_data, training=self.training)\n",
    "        \n",
    "        # Classification layer\n",
    "        y_score = self.cls_layer(net_data)\n",
    "        return y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_epochs = 25\n",
    "show_validation_score_every_epochs = 1\n",
    "embedding_size = 16\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca91dbe084dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Build Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_users_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_movies_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_predictions_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_users' is not defined"
     ]
    }
   ],
   "source": [
    "def mse_loss(predictions, target):\n",
    "    return torch.mean((predictions - target) ** 2)\n",
    "\n",
    "# Build Dataloaders\n",
    "train_users_torch = torch.tensor(train_users, device=device)\n",
    "train_movies_torch = torch.tensor(train_movies, device=device)\n",
    "train_predictions_torch = torch.tensor(train_predictions, device=device)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    TensorDataset(train_users_torch, train_movies_torch, train_predictions_torch),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_users_torch = torch.tensor(test_users, device=device)\n",
    "test_movies_torch = torch.tensor(test_movies, device=device)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TensorDataset(test_users_torch, test_movies_torch),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "ncf = NCF(number_of_users, number_of_movies, embedding_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(ncf.parameters(),\n",
    "                       lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
