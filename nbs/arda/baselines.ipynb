{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDOfjxut8kn8"
   },
   "source": [
    "## Project 1 - Collaborative Filtering\n",
    "\n",
    "### ETH Computational Intelligence Lab 2021 - Project 1 \n",
    "\n",
    "Disclaimer: Most methods mentioned here are briefly presented and not optimized. A solid baseline comparison may explore ways to optimize these. \n",
    "\n",
    "The problem of collaborative filtering concerns providing users with personalized product recommendations. The growth of e-commerce and social media platforms has established the need for recommender systems capable of providing personalized product recommendations. Here we resolve to past user behavior and exploit data dependencies to predict preferences for specific user-item interactions. \n",
    "\n",
    "This problem attracted great interest by the introduction of the [Netflix Prize](https://www.netflixprize.com/) that aimed to improve recommendations of Netflix's own algorithm. Given a list of users-items interactions, the task is to predict a series of ratings for another list of future interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZPDqL8jtUE4"
   },
   "source": [
    "In our setting, we are dealing with a smaller dataset. \n",
    "\n",
    "We are given a set of $N = 1,176,952$ integer movie ratings, ranging from $1$ to $5$, that are assigned by $m=10,000$ users to $n=1,000$ movies. A rating $r_{ui}$ indicates the preference by user $u$ of item $i$. Let $\\mathcal{\\Omega} = \\{(u,i) : r_{ui} \\text{ is known} \\}$ be the set of user and movie indices for which the ratings are known. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "T9eOB60Fz1ah"
   },
   "outputs": [],
   "source": [
    "#@title Basic Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBb6Q1hTNEc5"
   },
   "source": [
    "To download the data make sure you have joined the kaggle competition. Then create an api key through kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIoP9SO9tTZu",
    "outputId": "7465b19d-4e05-4543-d4db-e012cdf72b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id  Prediction\n",
      "0  r44_c1           4\n",
      "1  r61_c1           3\n",
      "2  r67_c1           4\n",
      "3  r72_c1           3\n",
      "4  r86_c1           5\n",
      "\n",
      "Shape (1176952, 2)\n"
     ]
    }
   ],
   "source": [
    "number_of_users, number_of_movies = (10000, 1000)\n",
    "\n",
    "data_pd = pd.read_csv('../data/data_train.csv')\n",
    "print(data_pd.head(5))\n",
    "print()\n",
    "print('Shape', data_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0Mq0onIvIQJ"
   },
   "source": [
    "The provided data $\\mathcal{\\Omega}$ are split into two disjoint subsets, namely $\\mathcal{\\Omega}_{\\text{train}}$ and $\\mathcal{\\Omega}_{\\text{test}}$. The former consists of $90\\%$ of the data and is used for training the individual models whereas the latter consists of the remaining $10\\%$ of the data and is used for learning optimal blending weights. Depending on your method, you may choose to retrain on the whole dataset for the final solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_aMzkPDhvHn0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into train and test\n",
    "\n",
    "train_size = 0.9\n",
    "\n",
    "train_pd, test_pd = train_test_split(data_pd, train_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRZiZQepwqZx"
   },
   "source": [
    "Preprocess data by creating a $m \\times n$ matrix\n",
    "\n",
    "$$A_{ui} = \\begin{cases} \n",
    "      r_{ui} & \\text{ if } (u,i) \\in \\mathcal{\\Omega}_{\\text{train}} \\\\\n",
    "      0 & \\text{ else }\n",
    "\\end{cases}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UMkePwnYvHqt"
   },
   "outputs": [],
   "source": [
    "def extract_users_items_predictions(data_pd):\n",
    "    users, movies = \\\n",
    "        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
    "    predictions = data_pd.Prediction.values\n",
    "    return users, movies, predictions\n",
    "\n",
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "# also create full matrix of observed values\n",
    "data = np.full((number_of_users, number_of_movies), np.mean(train_pd.Prediction.values))\n",
    "mask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpFuZ2-g0TsJ"
   },
   "source": [
    "To consider:\n",
    "* Do unobserved values matter for the method we are using? If yes, is the above initialization the best?\n",
    "* Does normalization of the data matter for the method we are using?\n",
    "* If yes, should we do the same transformations for the test data?\n",
    "\n",
    "Our task is to predict ratings according to specific users-movies combinations. We will quantify the quality of our predictions based on the root mean squared error (RMSE) function between the true and observed ratings. For a given set of observations $ \\mathcal{\\Omega}$, let\n",
    "\\begin{equation}\n",
    "    \\text{RMSE} = \\sqrt{\\frac{1}{|\\mathcal{\\Omega}|}\\sum_{ (u,i) \\in \\mathcal{\\Omega}} \\big(r_{ui} - \\hat{r}_{ui}\\big)^2}\n",
    "\\end{equation}\n",
    "where $\\hat{r}_{ui}$ denotes the estimate of $r_{ui}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IIthYlM56E1B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = lambda x, y: math.sqrt(mean_squared_error(x, y))\n",
    "\n",
    "test_users, test_movies, test_predictions = extract_users_items_predictions(test_pd)\n",
    "\n",
    "# test our predictions with the true values\n",
    "def get_score(predictions, target_values=test_predictions):\n",
    "    return rmse(predictions, target_values)\n",
    "\n",
    "def extract_prediction_from_full_matrix(reconstructed_matrix, users=test_users, movies=test_movies):\n",
    "    # returns predictions for the users-movies combinations specified based on a full m \\times n matrix\n",
    "    assert(len(users) == len(movies)), \"users-movies combinations specified should have equal length\"\n",
    "    predictions = np.zeros(len(test_users))\n",
    "\n",
    "    for i, (user, movie) in enumerate(zip(users, movies)):\n",
    "        predictions[i] = reconstructed_matrix[user][movie]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dGaNnI_20pe"
   },
   "source": [
    "# Methods and Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8URW5hbgjIY"
   },
   "source": [
    "## General Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJ5Hiu25ghGz",
    "outputId": "e52c2ae0-d6f5-4657-ab70-1bf724a99e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1200\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "# also create full matrix of observed values\n",
    "data = np.full((number_of_users, number_of_movies), np.mean(train_pd.Prediction.values))\n",
    "\n",
    "reconstructed_matrix = data\n",
    "\n",
    "predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "\n",
    "print(\"RMSE: {:.4f}\".format(get_score(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwm5q8wPg3GD"
   },
   "source": [
    "## User Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPei8iEgg5XP",
    "outputId": "1c6b2a90-6566-4d76-a482-dc3d568ca987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2675\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "def calculate_user_means(train_users, train_predictions):\n",
    "    train_user_predictions_mapping = {}\n",
    "    for train_user, train_prediction in zip(train_users, train_predictions):\n",
    "        if train_user in train_user_predictions_mapping.keys():\n",
    "            train_user_predictions_mapping[train_user].append(train_prediction)\n",
    "        else:\n",
    "            train_user_predictions_mapping[train_user] = [train_prediction]\n",
    "    train_user_prediction_mean_mapping = {}\n",
    "    for key, value in train_user_predictions_mapping.items():\n",
    "        train_user_prediction_mean_mapping[key] = np.mean(value)\n",
    "    return train_user_prediction_mean_mapping\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "\n",
    "train_user_prediction_mean_mapping = calculate_user_means(train_users, train_predictions)\n",
    "\n",
    "for user, movie in zip(test_users.tolist(), test_movies.tolist()):\n",
    "    data[user][movie] = train_user_prediction_mean_mapping[user]\n",
    "\n",
    "reconstructed_matrix = data\n",
    "\n",
    "predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "\n",
    "print(\"RMSE: {:.4f}\".format(get_score(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inQhaVlShtJJ"
   },
   "source": [
    "## Movie Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0oqTRufhzmE",
    "outputId": "45b5cf3c-27e3-4c10-de30-116b9b8fd2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3312\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "def calculate_movie_means(train_movies, train_predictions):\n",
    "    train_movie_predictions_mapping = {}\n",
    "    for train_movie, train_prediction in zip(train_movies, train_predictions):\n",
    "        if train_movie in train_movie_predictions_mapping.keys():\n",
    "            train_movie_predictions_mapping[train_movie].append(train_prediction)\n",
    "        else:\n",
    "            train_movie_predictions_mapping[train_movie] = [train_prediction]\n",
    "    train_movie_prediction_mean_mapping = {}\n",
    "    for key, value in train_movie_predictions_mapping.items():\n",
    "        train_movie_prediction_mean_mapping[key] = np.mean(value)\n",
    "    return train_movie_prediction_mean_mapping\n",
    "\n",
    "# also create full matrix of observed values\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "\n",
    "train_movie_prediction_mean_mapping = calculate_movie_means(train_movies, train_predictions)\n",
    "\n",
    "for user, movie in zip(test_users.tolist(), test_movies.tolist()):\n",
    "    data[user][movie] = train_user_prediction_mean_mapping[movie]\n",
    "\n",
    "reconstructed_matrix = data\n",
    "\n",
    "predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "\n",
    "print(\"RMSE: {:.4f}\".format(get_score(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-3ZuqwW5HKl"
   },
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "Assuming that column entries are not random, we attempt to fill the missing entries by capturing some of the most significant components of the underlying data. Assume that a latent factor model associates each user $u$ with a set of user factors $ p_u \\in \\mathbb{R}^k$ and each item $i$ with a set of item factors $ q_i \\in \\mathbb{R}^k$. In the case of movies, some of these factors could correspond to movie genres such as comedy, drama, action etc. For each item $i$, the elements of $ q_i$ quantify the extent to which the item possesses these factors. Similarly, for each user $u$, the elements of $ p_u$ measure the level of interest that the user has to each of these factors. In this framework, user-item interactions are modeled by inner products in the latent space, leading to the following prediction rule \n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} =  p_u^T q_i.\n",
    "\\end{equation}\n",
    "\n",
    "Singular Value Decomposition (SVD) [1] is a widely used technique for matrix factorization. Any matrix $ M \\in \\mathbb{R}^{m \\times n}$ can be decomposed into $A = U \\Sigma V^T$, where $ U \\in \\mathbb{R}^{m\\times m}$, $ \\Sigma \\in \\mathbb{R}^{m \\times n}$ and $ V \\in \\mathbb{R}^{n \\times n}$. Matrices $ U$ and $ V$ are orthogonal, whereas $ \\Sigma$ has $ rank(A)$ positive entries on the main diagonal sorted in decreasing order of value. \n",
    "\n",
    "We apply the SVD on the imputed user-item matrix to decompose it into $A =  U  \\Sigma  V^T$. We may assume that a list of $k$ distinguishes users' interests and movies' characteristics. This motivates us to approximate $A$ by another matrix of low rank. The Eckart-Young theorem [2] states that the optimal (in terms of the Frobenius norm objective) rank $k$ approximation of the matrix $A$ is given by $A_k =  U_k  \\Sigma_k  V^T_k$, where $ U_k \\in \\mathbb{R}^{m \\times k}$, $ \\Sigma_k \\in \\mathbb{R}^{k \\times k}$ and $ V_k \\in \\mathbb{R}^{n \\times k}$. $ U_k$ and $ V_k$ correspond to the first $k$ columns of $ U$ and $ V$ respectively and $ \\Sigma_k$ to the $k \\times k$ sub-matrix of $ \\Sigma$ containing the $k$ largest singular values. \n",
    "\n",
    "----------------\n",
    "[1] Klema, Virginia, and Alan Laub. \"The singular value decomposition: Its computation and some applications.\" IEEE Transactions on automatic control 25.2 (1980): 164-176.\n",
    "\n",
    "[2] Eckart, Carl, and Gale Young. \"The approximation of one matrix by another of lower rank.\" Psychometrika 1.3 (1936): 211-218."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW4fkJlC05Sn"
   },
   "source": [
    "How many singular values should we keep? Try them all!\n",
    "This is why we first use a train-validation split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzFUvzpzpGKp"
   },
   "source": [
    "## Vanilla SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "incWlq0G5Go7",
    "outputId": "198a41e5-79de-4974-88ce-04dc013f6b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using SVD is: 1.0657\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), np.mean(train_pd.Prediction.values))\n",
    "mask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "k_singular_values = 10\n",
    "number_of_singular_values = min(number_of_users, number_of_movies)\n",
    "\n",
    "assert(k_singular_values <= number_of_singular_values), \"choose correct number of singular values\"\n",
    "\n",
    "U, s, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "\n",
    "S = np.zeros((number_of_movies, number_of_movies))\n",
    "S[:k_singular_values, :k_singular_values] = np.diag(s[:k_singular_values])\n",
    "\n",
    "reconstructed_matrix = U.dot(S).dot(Vt)\n",
    "    \n",
    "predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "\n",
    "print(\"RMSE using SVD is: {:.4f}\".format(get_score(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6grZSCckUEo"
   },
   "source": [
    "## SVD with user-based standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFjasKZUkRp2",
    "outputId": "a73dff0e-570b-4bea-8cbf-61b96b667807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0726\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "def standardize_train_predictions(train_users, train_predictions):\n",
    "    train_user_predictions_mapping = {}\n",
    "    for train_user, train_prediction in zip(train_users, train_predictions):\n",
    "        if train_user in train_user_predictions_mapping.keys():\n",
    "            train_user_predictions_mapping[train_user].append(train_prediction)\n",
    "        else:\n",
    "            train_user_predictions_mapping[train_user] = [train_prediction]\n",
    "\n",
    "    train_user_prediction_mean_mapping = {}\n",
    "    train_user_prediction_std_mapping = {}\n",
    "    for key, value in train_user_predictions_mapping.items():\n",
    "        train_user_prediction_mean_mapping[key] = np.mean(value)\n",
    "        train_user_prediction_std_mapping[key] = np.std(value)\n",
    "\n",
    "    df = pd.DataFrame.from_dict({\"train_user\": train_users, \"train_predictions\": train_predictions})\n",
    "    df[\"train_predictions\"] = df.apply(lambda x: (x[\"train_predictions\"] - train_user_prediction_mean_mapping[x[\"train_user\"]]) / train_user_prediction_std_mapping[x[\"train_user\"]], axis=1)\n",
    "    return df[\"train_predictions\"].values, train_user_prediction_mean_mapping, train_user_prediction_std_mapping\n",
    "\n",
    "def unstandardize_test_predictions(test_users, test_predictions, train_user_prediction_mean_mapping, train_user_prediction_std_mapping):\n",
    "    df = pd.DataFrame.from_dict({\"test_user\": test_users, \"test_predictions\": test_predictions})\n",
    "    df[\"test_predictions\"] = df.apply(lambda x: (x[\"test_predictions\"] * train_user_prediction_std_mapping[x[\"test_user\"]]) + train_user_prediction_mean_mapping[x[\"test_user\"]], axis=1)\n",
    "    return df[\"test_predictions\"].values\n",
    "\n",
    "standardized_train_predictions, train_user_prediction_mean_mapping, train_user_prediction_std_mapping = standardize_train_predictions(train_users, train_predictions)\n",
    "\n",
    "unstandardized_train_predictions = unstandardize_test_predictions(train_users, standardized_train_predictions, train_user_prediction_mean_mapping, train_user_prediction_std_mapping)\n",
    "\n",
    "assert np.allclose(unstandardized_train_predictions, train_predictions), \"Unstandardized train predictions are different than original train predictions\"\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "mask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, standardized_train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "k_singular_values = 10\n",
    "number_of_singular_values = min(number_of_users, number_of_movies)\n",
    "\n",
    "assert(k_singular_values <= number_of_singular_values), \"choose correct number of singular values\"\n",
    "\n",
    "U, s, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "\n",
    "S = np.zeros((number_of_movies, number_of_movies))\n",
    "S[:k_singular_values, :k_singular_values] = np.diag(s[:k_singular_values])\n",
    "\n",
    "reconstructed_matrix = U.dot(S).dot(Vt)\n",
    "\n",
    "standardized_test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "unstandardized_test_predictions = unstandardize_test_predictions(test_users, standardized_test_predictions, train_user_prediction_mean_mapping, train_user_prediction_std_mapping)\n",
    "\n",
    "print(\"RMSE: {:.4f}\".format(get_score(unstandardized_test_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2fwcfgOo7lH"
   },
   "source": [
    "## SVD with movie based standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUoPOUaPo6mi",
    "outputId": "7ece61c5-48cb-4ce0-a0f8-ab4f1ac52618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0237\n"
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "def standardize_train_predictions(train_movies, train_predictions):\n",
    "    train_movie_predictions_mapping = {}\n",
    "    for train_movie, train_prediction in zip(train_movies, train_predictions):\n",
    "        if train_movie in train_movie_predictions_mapping.keys():\n",
    "            train_movie_predictions_mapping[train_movie].append(train_prediction)\n",
    "        else:\n",
    "            train_movie_predictions_mapping[train_movie] = [train_prediction]\n",
    "\n",
    "    train_movie_prediction_mean_mapping = {}\n",
    "    train_movie_prediction_std_mapping = {}\n",
    "    for key, value in train_movie_predictions_mapping.items():\n",
    "        train_movie_prediction_mean_mapping[key] = np.mean(value)\n",
    "        train_movie_prediction_std_mapping[key] = np.std(value)\n",
    "\n",
    "    df = pd.DataFrame.from_dict({\"train_movie\": train_movies, \"train_predictions\": train_predictions})\n",
    "    df[\"train_predictions\"] = df.apply(lambda x: (x[\"train_predictions\"] - train_movie_prediction_mean_mapping[x[\"train_movie\"]]) / train_movie_prediction_std_mapping[x[\"train_movie\"]], axis=1)\n",
    "    return df[\"train_predictions\"].values, train_movie_prediction_mean_mapping, train_movie_prediction_std_mapping\n",
    "\n",
    "def unstandardize_test_predictions(test_movies, test_predictions, train_movie_prediction_mean_mapping, train_movie_prediction_std_mapping):\n",
    "    df = pd.DataFrame.from_dict({\"test_movie\": test_movies, \"test_predictions\": test_predictions})\n",
    "    df[\"test_predictions\"] = df.apply(lambda x: (x[\"test_predictions\"] * train_movie_prediction_std_mapping[x[\"test_movie\"]]) + train_movie_prediction_mean_mapping[x[\"test_movie\"]], axis=1)\n",
    "    return df[\"test_predictions\"].values\n",
    "\n",
    "standardized_train_predictions, train_movie_prediction_mean_mapping, train_movie_prediction_std_mapping = standardize_train_predictions(train_movies, train_predictions)\n",
    "\n",
    "unstandardized_train_predictions = unstandardize_test_predictions(train_movies, standardized_train_predictions, train_movie_prediction_mean_mapping, train_movie_prediction_std_mapping)\n",
    "\n",
    "assert np.allclose(unstandardized_train_predictions, train_predictions), \"Unstandardized train predictions are different than original train predictions\"\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "mask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, standardized_train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "k_singular_values = 10\n",
    "number_of_singular_values = min(number_of_users, number_of_movies)\n",
    "\n",
    "assert(k_singular_values <= number_of_singular_values), \"choose correct number of singular values\"\n",
    "\n",
    "U, s, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "\n",
    "S = np.zeros((number_of_movies, number_of_movies))\n",
    "S[:k_singular_values, :k_singular_values] = np.diag(s[:k_singular_values])\n",
    "\n",
    "reconstructed_matrix = U.dot(S).dot(Vt)\n",
    "\n",
    "standardized_test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "unstandardized_test_predictions = unstandardize_test_predictions(test_movies, standardized_test_predictions, train_movie_prediction_mean_mapping, train_movie_prediction_std_mapping)\n",
    "\n",
    "print(\"RMSE: {:.4f}\".format(get_score(unstandardized_test_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxbpw8GjDl7F"
   },
   "source": [
    "To consider:\n",
    "* How can we improve SVD? As aforementioned initialization of unobserved values matters for SVD.\n",
    "* Can we use SVD iteratively to better initialize unobserved values?\n",
    "* Maybe start from a low-rank reconstruction and after you have ensured better initialization increase the reconstruction rank.\n",
    "* Can we make adjustments to SVD? Other variations exist, see e.g. [1, 2], Singular Value Projection, Nuclear Norm Relaxation ...\n",
    " \n",
    "--------------\n",
    "[1] Cai, Jian-Feng, Emmanuel J. Candès, and Zuowei Shen. \"A singular value thresholding algorithm for matrix completion.\" SIAM Journal on optimization 20.4 (2010): 1956-1982.\n",
    " \n",
    "[2] Zarmehi, Nematollah, and Farokh Marvasti. \"Adaptive singular value thresholding.\" 2017 International Conference on Sampling Theory and Applications (SampTA). IEEE, 2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd7v02oMRrSl"
   },
   "source": [
    "## Alternating Least Squares (ALS)\n",
    " \n",
    "SVD is very sensitive to initialization. Can we propose a method that defines a loss function only on the user-items interactions observed and not the whole matrix? Regularizing the weights also improves stability and ensures simpler solutions in accordance with [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor).\n",
    " \n",
    "Can we propose a method that defines a loss function only on the user-items interactions observed? \n",
    "\n",
    "Our new objective is to minimize the following loss-function\n",
    "\\begin{equation}\n",
    "\\sum\\limits_{(u,i) \\in \\mathcal{\\Omega}_{\\text{train}}}(r_{ui} - p_u^T q_i)^2 + \\lambda\\sum_{u=1}^m\\| p_u\\|^2 + \\lambda\\sum\\limits_{i=1}^n \\| q_i\\|^2,\n",
    "\\end{equation}\n",
    "where $\\lambda$ denotes a tunable regularization parameter.\n",
    " \n",
    "How can we optimize this objective? In general it is a non-convex problem. Optimize using stochastic gradient descent.\n",
    " \n",
    " \n",
    "--------------\n",
    "[1] Koren, Yehuda, Robert Bell, and Chris Volinsky. \"Matrix factorization techniques for recommender systems.\" Computer 42.8 (2009): 30-37.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4oMKRR_2RhY"
   },
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "baZ_y-I-gRnE",
    "outputId": "ddcfc4d2-f9b6-4589-d30d-206a9fb648dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 68/10000 [00:00<00:14, 679.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 RMSE: 3.644720074160342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 801.41it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 107.82it/s]\n",
      "  1%|          | 67/10000 [00:00<00:14, 665.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 RMSE: 1.0413611987376221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 818.21it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 111.10it/s]\n",
      "  1%|          | 73/10000 [00:00<00:13, 725.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 RMSE: 1.0446876504569444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 828.70it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 109.81it/s]\n",
      "  1%|▏         | 140/10000 [00:00<00:14, 701.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 RMSE: 1.039942922642958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 779.75it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 92.44it/s]\n",
      "  1%|          | 73/10000 [00:00<00:13, 726.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 RMSE: 1.0369646620162045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 721.71it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 99.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "mask = np.zeros((number_of_users, number_of_movies))\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "# for k in [2, 5, 10, 25, 50, 100, 200, 500, 900]:\n",
    "#     for lmbd in [2e-5, 2e-3, 2e-1, 2, 200]:\n",
    "#         print(f\"k: {k}, lmbd: {lmdb}\")\n",
    "\n",
    "k = 10\n",
    "lmbd = 0.2\n",
    "lr = 0.5\n",
    "\n",
    "epochs = 5\n",
    "U = np.random.normal(loc=0.2, scale=0.2, size=(number_of_users, k))\n",
    "V = np.random.normal(loc=0.2, scale=0.2, size=(k, number_of_movies))\n",
    "\n",
    "# without sgd\n",
    "for epoch in range(epochs):\n",
    "    reconstructed_matrix = U.dot(V)\n",
    "    test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "    print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")\n",
    "    for i in tqdm(list(range(number_of_users))):\n",
    "        rated_movie_indices = np.argwhere(mask[i, :] == 1).ravel()\n",
    "        left = lmbd * np.eye(k)\n",
    "        right = np.zeros((k, 1))\n",
    "        for j in rated_movie_indices:\n",
    "            vj = V[:, j].reshape(-1, 1)\n",
    "            left += vj.dot(vj.T)\n",
    "            right += data[i, j] * vj\n",
    "        U[i, :] = np.linalg.inv(left).dot(right).ravel()\n",
    "    for j in tqdm(list(range(number_of_movies))):\n",
    "        rater_user_indices = np.argwhere(mask[:, j] == 1).ravel()\n",
    "        left = lmbd * np.eye(k)\n",
    "        right = np.zeros((k, 1))\n",
    "        for i in rater_user_indices:\n",
    "            ui = U[i, :].reshape(-1, 1)\n",
    "            left += ui.dot(ui.T)\n",
    "            right += data[i, j] * ui\n",
    "        V[:, j] = np.linalg.inv(left).dot(right).ravel()\n",
    "\n",
    "\n",
    "# with sgd v1\n",
    "# for epoch in range(epochs):\n",
    "#     reconstructed_matrix = U.dot(V)\n",
    "#     test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "#     print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")\n",
    "#     for i in tqdm(list(range(number_of_users))):\n",
    "#         rated_movie_indices = np.argwhere(mask[i, :] == 1).ravel()\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for j in rated_movie_indices:\n",
    "#             vj = V[:, j].reshape(-1, 1)\n",
    "#             left += vj.dot(vj.T)\n",
    "#             right += data[i, j] * vj\n",
    "#         U[i, :] = (1 - lr) * U[i, :] + lr * np.linalg.inv(left).dot(right).ravel()\n",
    "#     for j in tqdm(list(range(number_of_movies))):\n",
    "#         rater_user_indices = np.argwhere(mask[:, j] == 1).ravel()\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for i in rater_user_indices:\n",
    "#             ui = U[i, :].reshape(-1, 1)\n",
    "#             left += ui.dot(ui.T)\n",
    "#             right += data[i, j] * ui\n",
    "#         V[:, j] = (1 - lr) * V[:, j] + lr * np.linalg.inv(left).dot(right).ravel()\n",
    "\n",
    "\n",
    "# with sgd v2\n",
    "# for epoch in range(epochs):\n",
    "#     if epoch % 100 == 0:\n",
    "#         reconstructed_matrix = U.dot(V)\n",
    "#         test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "#         print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")\n",
    "#     \n",
    "#     if np.random.random() > 0.9:\n",
    "#         i = np.random.randint(low=0, high=U.shape[0])\n",
    "#         rated_movie_indices = np.argwhere(mask[i, :] == 1).ravel()\n",
    "#         ui = U[i, :].reshape(-1, 1)\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for j in rated_movie_indices:\n",
    "#             vj = V[:, j].reshape(-1, 1)\n",
    "#             left += vj.dot(vj.T)\n",
    "#             right += data[i, j] * vj\n",
    "#         U[i, :] -= lr * (left.dot(ui) - right).ravel()\n",
    "#     else:\n",
    "#         j = np.random.randint(low=0, high=V.shape[1])\n",
    "#         rater_user_indices = np.argwhere(mask[:, j] == 1).ravel()\n",
    "#         vj = V[:, j].reshape(-1, 1)\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for i in rater_user_indices:\n",
    "#             ui = U[i, :].reshape(-1, 1)\n",
    "#             left += ui.dot(ui.T)\n",
    "#             right += data[i, j] * ui\n",
    "#         V[:, j] -= lr * (left.dot(vj) - right).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 RMSE: 1.2983947777292975\n",
      "Epoch: 1000000 RMSE: 1.2828230806834098\n",
      "Epoch: 2000000 RMSE: 1.2699988049199753\n",
      "Epoch: 3000000 RMSE: 1.2590684733709923\n",
      "Epoch: 4000000 RMSE: 1.249863668167971\n",
      "Epoch: 5000000 RMSE: 1.2419179494147836\n",
      "Epoch: 6000000 RMSE: 1.235013800555504\n",
      "Epoch: 7000000 RMSE: 1.2288946078709284\n",
      "Epoch: 8000000 RMSE: 1.2234130203916367\n",
      "Epoch: 9000000 RMSE: 1.2185490407504365\n",
      "Epoch: 10000000 RMSE: 1.2141557179542324\n",
      "Epoch: 11000000 RMSE: 1.2101641021899745\n",
      "Epoch: 12000000 RMSE: 1.2064512652781751\n",
      "Epoch: 13000000 RMSE: 1.2031019177186328\n",
      "Epoch: 14000000 RMSE: 1.199939471991511\n",
      "Epoch: 15000000 RMSE: 1.1969740364739037\n",
      "Epoch: 16000000 RMSE: 1.194241623375147\n",
      "Epoch: 17000000 RMSE: 1.1917293643929643\n",
      "Epoch: 18000000 RMSE: 1.1893349859490998\n",
      "Epoch: 19000000 RMSE: 1.1870720989517418\n",
      "Epoch: 20000000 RMSE: 1.184954659853109\n",
      "Epoch: 21000000 RMSE: 1.182881205745821\n",
      "Epoch: 22000000 RMSE: 1.180953391801266\n",
      "Epoch: 23000000 RMSE: 1.1791149448245648\n",
      "Epoch: 24000000 RMSE: 1.17736444526853\n",
      "Epoch: 25000000 RMSE: 1.1756412751308585\n",
      "Epoch: 26000000 RMSE: 1.174019076343325\n",
      "Epoch: 27000000 RMSE: 1.1724464127885308\n",
      "Epoch: 28000000 RMSE: 1.1709328283206664\n",
      "Epoch: 29000000 RMSE: 1.169416853012184\n",
      "Epoch: 30000000 RMSE: 1.1680130894689211\n",
      "Epoch: 31000000 RMSE: 1.16661292199588\n",
      "Epoch: 32000000 RMSE: 1.1652846822190173\n",
      "Epoch: 33000000 RMSE: 1.1639853469571835\n",
      "Epoch: 34000000 RMSE: 1.16270319257075\n",
      "Epoch: 35000000 RMSE: 1.161499284396945\n",
      "Epoch: 36000000 RMSE: 1.1602767537318892\n",
      "Epoch: 37000000 RMSE: 1.1591132698518167\n",
      "Epoch: 38000000 RMSE: 1.1580040598398547\n",
      "Epoch: 39000000 RMSE: 1.156890833838139\n",
      "Epoch: 40000000 RMSE: 1.155792333325542\n",
      "Epoch: 41000000 RMSE: 1.1547640239788255\n",
      "Epoch: 42000000 RMSE: 1.1537391526901966\n",
      "Epoch: 43000000 RMSE: 1.152690220290766\n",
      "Epoch: 44000000 RMSE: 1.1517134708062462\n",
      "Epoch: 45000000 RMSE: 1.1507154570980274\n",
      "Epoch: 46000000 RMSE: 1.1497657445025806\n",
      "Epoch: 47000000 RMSE: 1.1488030396991906\n",
      "Epoch: 48000000 RMSE: 1.1479070124059838\n",
      "Epoch: 49000000 RMSE: 1.1470533235166995\n",
      "Epoch: 50000000 RMSE: 1.146133522621248\n",
      "Epoch: 51000000 RMSE: 1.1452604523209038\n",
      "Epoch: 52000000 RMSE: 1.1443594411894242\n",
      "Epoch: 53000000 RMSE: 1.1434926825960878\n",
      "Epoch: 54000000 RMSE: 1.142627524244948\n",
      "Epoch: 55000000 RMSE: 1.1418206307988004\n",
      "Epoch: 56000000 RMSE: 1.14099909931574\n",
      "Epoch: 57000000 RMSE: 1.1401897715540978\n",
      "Epoch: 58000000 RMSE: 1.1393920069193457\n",
      "Epoch: 59000000 RMSE: 1.138599887424074\n",
      "Epoch: 60000000 RMSE: 1.1378182096282763\n",
      "Epoch: 61000000 RMSE: 1.1370861500435543\n",
      "Epoch: 62000000 RMSE: 1.1363187116525626\n",
      "Epoch: 63000000 RMSE: 1.135580125761961\n",
      "Epoch: 64000000 RMSE: 1.1348642016377601\n",
      "Epoch: 65000000 RMSE: 1.134151203039155\n",
      "Epoch: 66000000 RMSE: 1.1334197303776516\n",
      "Epoch: 67000000 RMSE: 1.1327063459889235\n",
      "Epoch: 68000000 RMSE: 1.1319923203900941\n",
      "Epoch: 69000000 RMSE: 1.1313099988316124\n",
      "Epoch: 70000000 RMSE: 1.130613333008776\n",
      "Epoch: 71000000 RMSE: 1.129934249341556\n",
      "Epoch: 72000000 RMSE: 1.1292480756195886\n",
      "Epoch: 73000000 RMSE: 1.1285738484446481\n",
      "Epoch: 74000000 RMSE: 1.127906625792481\n",
      "Epoch: 75000000 RMSE: 1.1272378261896692\n",
      "Epoch: 76000000 RMSE: 1.1265777499131455\n",
      "Epoch: 77000000 RMSE: 1.1259530369722197\n",
      "Epoch: 78000000 RMSE: 1.1253288682423794\n",
      "Epoch: 79000000 RMSE: 1.124711280852312\n",
      "Epoch: 80000000 RMSE: 1.1241013680865393\n",
      "Epoch: 81000000 RMSE: 1.123470828599379\n",
      "Epoch: 82000000 RMSE: 1.1228398865714035\n",
      "Epoch: 83000000 RMSE: 1.1222507942540052\n",
      "Epoch: 84000000 RMSE: 1.1216703884215853\n",
      "Epoch: 85000000 RMSE: 1.1210834382854784\n",
      "Epoch: 86000000 RMSE: 1.1204972898239256\n",
      "Epoch: 87000000 RMSE: 1.1199135158127116\n",
      "Epoch: 88000000 RMSE: 1.1193191765964698\n",
      "Epoch: 89000000 RMSE: 1.118735403111673\n",
      "Epoch: 90000000 RMSE: 1.1181766803350603\n",
      "Epoch: 91000000 RMSE: 1.1176614056468939\n",
      "Epoch: 92000000 RMSE: 1.1171156061307375\n",
      "Epoch: 93000000 RMSE: 1.1165657985436654\n",
      "Epoch: 94000000 RMSE: 1.1160050460705644\n",
      "Epoch: 95000000 RMSE: 1.1154507446177893\n",
      "Epoch: 96000000 RMSE: 1.1148798004817444\n",
      "Epoch: 97000000 RMSE: 1.114343170139925\n",
      "Epoch: 98000000 RMSE: 1.1138214070995482\n",
      "Epoch: 99000000 RMSE: 1.1133050585863413\n",
      "Epoch: 100000000 RMSE: 1.1127962815182153\n",
      "Epoch: 101000000 RMSE: 1.1122460415388555\n",
      "Epoch: 102000000 RMSE: 1.111740101695946\n",
      "Epoch: 103000000 RMSE: 1.111255215198154\n",
      "Epoch: 104000000 RMSE: 1.1107613500752416\n",
      "Epoch: 105000000 RMSE: 1.1102628381265445\n",
      "Epoch: 106000000 RMSE: 1.1097406827931138\n",
      "Epoch: 107000000 RMSE: 1.1092509287819279\n",
      "Epoch: 108000000 RMSE: 1.1087622115548805\n",
      "Epoch: 109000000 RMSE: 1.1083024403515158\n",
      "Epoch: 110000000 RMSE: 1.1078274411256601\n",
      "Epoch: 111000000 RMSE: 1.107350742847437\n",
      "Epoch: 112000000 RMSE: 1.1068500668445218\n",
      "Epoch: 113000000 RMSE: 1.1063891995700108\n",
      "Epoch: 114000000 RMSE: 1.105931921411443\n",
      "Epoch: 115000000 RMSE: 1.1054860357122838\n",
      "Epoch: 116000000 RMSE: 1.1050344510766053\n",
      "Epoch: 117000000 RMSE: 1.1045624314700955\n",
      "Epoch: 118000000 RMSE: 1.1041235665201068\n",
      "Epoch: 119000000 RMSE: 1.1036795745631873\n",
      "Epoch: 120000000 RMSE: 1.1032042897198469\n",
      "Epoch: 121000000 RMSE: 1.102753214136119\n",
      "Epoch: 122000000 RMSE: 1.1023242723082618\n",
      "Epoch: 123000000 RMSE: 1.1018928718051078\n",
      "Epoch: 124000000 RMSE: 1.1014656842950064\n",
      "Epoch: 125000000 RMSE: 1.1010652426446748\n",
      "Epoch: 126000000 RMSE: 1.100638746875133\n",
      "Epoch: 127000000 RMSE: 1.1002056206879678\n",
      "Epoch: 128000000 RMSE: 1.0997850428805267\n",
      "Epoch: 129000000 RMSE: 1.099367659035679\n",
      "Epoch: 130000000 RMSE: 1.0989433262129935\n",
      "Epoch: 131000000 RMSE: 1.0985572369103647\n",
      "Epoch: 132000000 RMSE: 1.0981571505511367\n",
      "Epoch: 133000000 RMSE: 1.0977606482479647\n",
      "Epoch: 134000000 RMSE: 1.0974065636347958\n",
      "Epoch: 135000000 RMSE: 1.0970254266879247\n",
      "Epoch: 136000000 RMSE: 1.0966352673194695\n",
      "Epoch: 137000000 RMSE: 1.0962683110163005\n",
      "Epoch: 138000000 RMSE: 1.0958871483168207\n",
      "Epoch: 139000000 RMSE: 1.0954765759049256\n",
      "Epoch: 140000000 RMSE: 1.0951011492947678\n",
      "Epoch: 141000000 RMSE: 1.0947013204646328\n",
      "Epoch: 142000000 RMSE: 1.0943419492165571\n",
      "Epoch: 143000000 RMSE: 1.093957996584519\n",
      "Epoch: 144000000 RMSE: 1.0935674792157957\n",
      "Epoch: 145000000 RMSE: 1.0932041916580721\n",
      "Epoch: 146000000 RMSE: 1.0928313849112044\n",
      "Epoch: 147000000 RMSE: 1.092469609609346\n",
      "Epoch: 148000000 RMSE: 1.0921039754045052\n",
      "Epoch: 149000000 RMSE: 1.0917298789970484\n",
      "Epoch: 150000000 RMSE: 1.091367760620566\n",
      "Epoch: 151000000 RMSE: 1.091010793835245\n",
      "Epoch: 152000000 RMSE: 1.0906375115664209\n",
      "Epoch: 153000000 RMSE: 1.0902798946611365\n",
      "Epoch: 154000000 RMSE: 1.0899208250507362\n",
      "Epoch: 155000000 RMSE: 1.0895617440040701\n",
      "Epoch: 156000000 RMSE: 1.0892231171030031\n",
      "Epoch: 157000000 RMSE: 1.0888991975777575\n",
      "Epoch: 158000000 RMSE: 1.088536179970083\n",
      "Epoch: 159000000 RMSE: 1.088218599107448\n",
      "Epoch: 160000000 RMSE: 1.0878972320450684\n",
      "Epoch: 161000000 RMSE: 1.0875611351901866\n",
      "Epoch: 162000000 RMSE: 1.087239664877582\n",
      "Epoch: 163000000 RMSE: 1.0869221203513757\n",
      "Epoch: 164000000 RMSE: 1.0866100392359181\n",
      "Epoch: 165000000 RMSE: 1.086273852037369\n",
      "Epoch: 166000000 RMSE: 1.0859442085089617\n",
      "Epoch: 167000000 RMSE: 1.0856376172627158\n",
      "Epoch: 168000000 RMSE: 1.0853251291218746\n",
      "Epoch: 169000000 RMSE: 1.0850022026301231\n",
      "Epoch: 170000000 RMSE: 1.0846851561055477\n",
      "Epoch: 171000000 RMSE: 1.0843705254113076\n",
      "Epoch: 172000000 RMSE: 1.0840850685440306\n",
      "Epoch: 173000000 RMSE: 1.0837632041645835\n",
      "Epoch: 174000000 RMSE: 1.0834636466469914\n",
      "Epoch: 175000000 RMSE: 1.0831258483644486\n",
      "Epoch: 176000000 RMSE: 1.0828368823567986\n",
      "Epoch: 177000000 RMSE: 1.0825395882758044\n",
      "Epoch: 178000000 RMSE: 1.0822755797252337\n",
      "Epoch: 179000000 RMSE: 1.081985464785064\n",
      "Epoch: 180000000 RMSE: 1.0816970677614999\n",
      "Epoch: 181000000 RMSE: 1.0814290717517212\n",
      "Epoch: 182000000 RMSE: 1.081130890544496\n",
      "Epoch: 183000000 RMSE: 1.0808536974133194\n",
      "Epoch: 184000000 RMSE: 1.0805437752774607\n",
      "Epoch: 185000000 RMSE: 1.0802143372848352\n",
      "Epoch: 186000000 RMSE: 1.0799221846138112\n",
      "Epoch: 187000000 RMSE: 1.0796375086716368\n",
      "Epoch: 188000000 RMSE: 1.0793833707129312\n",
      "Epoch: 189000000 RMSE: 1.0791097804895153\n",
      "Epoch: 190000000 RMSE: 1.0788461660027884\n",
      "Epoch: 191000000 RMSE: 1.0785730734617514\n",
      "Epoch: 192000000 RMSE: 1.0782974131005674\n",
      "Epoch: 193000000 RMSE: 1.0780224349175178\n",
      "Epoch: 194000000 RMSE: 1.0777515061055547\n",
      "Epoch: 195000000 RMSE: 1.0774825720634393\n",
      "Epoch: 196000000 RMSE: 1.0771982438536503\n",
      "Epoch: 197000000 RMSE: 1.0769489559042658\n",
      "Epoch: 198000000 RMSE: 1.0766708435885384\n",
      "Epoch: 199000000 RMSE: 1.076420313527765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200000000 RMSE: 1.076148836051612\n",
      "Epoch: 201000000 RMSE: 1.0759195407981657\n",
      "Epoch: 202000000 RMSE: 1.0756696491510451\n",
      "Epoch: 203000000 RMSE: 1.0754167449772\n",
      "Epoch: 204000000 RMSE: 1.0751811881411912\n",
      "Epoch: 205000000 RMSE: 1.0749309050828422\n",
      "Epoch: 206000000 RMSE: 1.0746946850454289\n",
      "Epoch: 207000000 RMSE: 1.0744325011096088\n",
      "Epoch: 208000000 RMSE: 1.0741715189448129\n",
      "Epoch: 209000000 RMSE: 1.0739297405524981\n",
      "Epoch: 210000000 RMSE: 1.0736698287278978\n",
      "Epoch: 211000000 RMSE: 1.0734342132891246\n",
      "Epoch: 212000000 RMSE: 1.0731813117233768\n",
      "Epoch: 213000000 RMSE: 1.0729357527182974\n",
      "Epoch: 214000000 RMSE: 1.072713001441781\n",
      "Epoch: 215000000 RMSE: 1.0724921351280714\n",
      "Epoch: 216000000 RMSE: 1.0722616391416453\n",
      "Epoch: 217000000 RMSE: 1.0720043938204742\n",
      "Epoch: 218000000 RMSE: 1.0717902744557342\n",
      "Epoch: 219000000 RMSE: 1.071577178802869\n",
      "Epoch: 220000000 RMSE: 1.0713649215444327\n",
      "Epoch: 221000000 RMSE: 1.0711485243584784\n",
      "Epoch: 222000000 RMSE: 1.070906573127162\n",
      "Epoch: 223000000 RMSE: 1.0706483837463687\n",
      "Epoch: 224000000 RMSE: 1.0704283099918765\n",
      "Epoch: 225000000 RMSE: 1.0702368522630181\n",
      "Epoch: 226000000 RMSE: 1.0700448651007428\n",
      "Epoch: 227000000 RMSE: 1.0698245202438383\n",
      "Epoch: 228000000 RMSE: 1.0696239958324603\n",
      "Epoch: 229000000 RMSE: 1.0694180963570175\n",
      "Epoch: 230000000 RMSE: 1.0692214175571602\n",
      "Epoch: 231000000 RMSE: 1.0690362968736657\n",
      "Epoch: 232000000 RMSE: 1.0687987907030987\n",
      "Epoch: 233000000 RMSE: 1.0685926570923776\n",
      "Epoch: 234000000 RMSE: 1.0683800409279829\n",
      "Epoch: 235000000 RMSE: 1.06819193859597\n",
      "Epoch: 236000000 RMSE: 1.0679996080196996\n",
      "Epoch: 237000000 RMSE: 1.0678205830295042\n",
      "Epoch: 238000000 RMSE: 1.067623777410664\n",
      "Epoch: 239000000 RMSE: 1.067426665271057\n",
      "Epoch: 240000000 RMSE: 1.0672235079167844\n",
      "Epoch: 241000000 RMSE: 1.0670273636421033\n",
      "Epoch: 242000000 RMSE: 1.0668359265154346\n",
      "Epoch: 243000000 RMSE: 1.0666540538009457\n",
      "Epoch: 244000000 RMSE: 1.0664448325079592\n",
      "Epoch: 245000000 RMSE: 1.0662537479932146\n",
      "Epoch: 246000000 RMSE: 1.0660594763941447\n",
      "Epoch: 247000000 RMSE: 1.0658746974941515\n",
      "Epoch: 248000000 RMSE: 1.0656598738386787\n",
      "Epoch: 249000000 RMSE: 1.0654729180479314\n",
      "Epoch: 250000000 RMSE: 1.0653102365304932\n",
      "Epoch: 251000000 RMSE: 1.0651168106817435\n",
      "Epoch: 252000000 RMSE: 1.0649411521994256\n",
      "Epoch: 253000000 RMSE: 1.0647584933526408\n",
      "Epoch: 254000000 RMSE: 1.0645728881748238\n",
      "Epoch: 255000000 RMSE: 1.0644201901536139\n",
      "Epoch: 256000000 RMSE: 1.0642403199801855\n",
      "Epoch: 257000000 RMSE: 1.0640554908003579\n",
      "Epoch: 258000000 RMSE: 1.0638940109625095\n",
      "Epoch: 259000000 RMSE: 1.0637188505338586\n",
      "Epoch: 260000000 RMSE: 1.0635310432562577\n",
      "Epoch: 261000000 RMSE: 1.0633469860498783\n",
      "Epoch: 262000000 RMSE: 1.0631612227970106\n",
      "Epoch: 263000000 RMSE: 1.0629632675924559\n",
      "Epoch: 264000000 RMSE: 1.0628054657260995\n",
      "Epoch: 265000000 RMSE: 1.0626407747539681\n",
      "Epoch: 266000000 RMSE: 1.062485483293402\n",
      "Epoch: 267000000 RMSE: 1.0623231870834493\n",
      "Epoch: 268000000 RMSE: 1.0621557014407295\n",
      "Epoch: 269000000 RMSE: 1.0619961536507634\n",
      "Epoch: 270000000 RMSE: 1.0618288042426305\n",
      "Epoch: 271000000 RMSE: 1.061642220735277\n",
      "Epoch: 272000000 RMSE: 1.0614684111927362\n",
      "Epoch: 273000000 RMSE: 1.06132346800416\n",
      "Epoch: 274000000 RMSE: 1.0611687787082846\n",
      "Epoch: 275000000 RMSE: 1.0610219064142494\n",
      "Epoch: 276000000 RMSE: 1.0608471762670753\n",
      "Epoch: 277000000 RMSE: 1.0606766718290002\n",
      "Epoch: 278000000 RMSE: 1.0605167222639884\n",
      "Epoch: 279000000 RMSE: 1.0603719787235961\n",
      "Epoch: 280000000 RMSE: 1.060201914224919\n",
      "Epoch: 281000000 RMSE: 1.0600443437866318\n",
      "Epoch: 282000000 RMSE: 1.0598926613425095\n",
      "Epoch: 283000000 RMSE: 1.0597486708331236\n",
      "Epoch: 284000000 RMSE: 1.0596022651794645\n",
      "Epoch: 285000000 RMSE: 1.0594587033527287\n",
      "Epoch: 286000000 RMSE: 1.0593097230624877\n",
      "Epoch: 287000000 RMSE: 1.0591607947760988\n",
      "Epoch: 288000000 RMSE: 1.0590276600681336\n",
      "Epoch: 289000000 RMSE: 1.05887385538247\n",
      "Epoch: 290000000 RMSE: 1.0587438542793741\n",
      "Epoch: 291000000 RMSE: 1.0586029492056641\n",
      "Epoch: 292000000 RMSE: 1.0584388905637878\n",
      "Epoch: 293000000 RMSE: 1.0582813695703521\n",
      "Epoch: 294000000 RMSE: 1.058128449136564\n",
      "Epoch: 295000000 RMSE: 1.058010545417482\n",
      "Epoch: 296000000 RMSE: 1.0578618697126243\n",
      "Epoch: 297000000 RMSE: 1.0577261912166895\n",
      "Epoch: 298000000 RMSE: 1.0575958630058495\n",
      "Epoch: 299000000 RMSE: 1.0574672940664243\n",
      "Epoch: 300000000 RMSE: 1.0573496986404605\n",
      "Epoch: 301000000 RMSE: 1.0572225185781918\n",
      "Epoch: 302000000 RMSE: 1.057091456109232\n",
      "Epoch: 303000000 RMSE: 1.0569633654940198\n",
      "Epoch: 304000000 RMSE: 1.0568339004784373\n",
      "Epoch: 305000000 RMSE: 1.0566986258525504\n",
      "Epoch: 306000000 RMSE: 1.0565492992019778\n",
      "Epoch: 307000000 RMSE: 1.0564189382204632\n",
      "Epoch: 308000000 RMSE: 1.0562913833346017\n",
      "Epoch: 309000000 RMSE: 1.0561648112464008\n",
      "Epoch: 310000000 RMSE: 1.0560178036495853\n",
      "Epoch: 311000000 RMSE: 1.0558928252612638\n",
      "Epoch: 312000000 RMSE: 1.0557655059270765\n",
      "Epoch: 313000000 RMSE: 1.0556366682319265\n",
      "Epoch: 314000000 RMSE: 1.055536739938406\n",
      "Epoch: 315000000 RMSE: 1.0554258458793018\n",
      "Epoch: 316000000 RMSE: 1.055295965400104\n",
      "Epoch: 317000000 RMSE: 1.0551692763909772\n",
      "Epoch: 318000000 RMSE: 1.0550610663489566\n",
      "Epoch: 319000000 RMSE: 1.0549531105449976\n",
      "Epoch: 320000000 RMSE: 1.0548418919797506\n",
      "Epoch: 321000000 RMSE: 1.0547225707252768\n",
      "Epoch: 322000000 RMSE: 1.0545693524254367\n",
      "Epoch: 323000000 RMSE: 1.054454140648317\n",
      "Epoch: 324000000 RMSE: 1.054343285428579\n",
      "Epoch: 325000000 RMSE: 1.0542350014886392\n",
      "Epoch: 326000000 RMSE: 1.054131359579088\n",
      "Epoch: 327000000 RMSE: 1.054003844894027\n",
      "Epoch: 328000000 RMSE: 1.0538678541223725\n",
      "Epoch: 329000000 RMSE: 1.0537501568509988\n",
      "Epoch: 330000000 RMSE: 1.0536416130083688\n",
      "Epoch: 331000000 RMSE: 1.053489473596504\n",
      "Epoch: 332000000 RMSE: 1.0533530792517731\n",
      "Epoch: 333000000 RMSE: 1.053236655279792\n",
      "Epoch: 334000000 RMSE: 1.0531315787300772\n",
      "Epoch: 335000000 RMSE: 1.0530526141525505\n",
      "Epoch: 336000000 RMSE: 1.0529206210521285\n",
      "Epoch: 337000000 RMSE: 1.0528104391316593\n",
      "Epoch: 338000000 RMSE: 1.0527178965257695\n",
      "Epoch: 339000000 RMSE: 1.0526261955076774\n",
      "Epoch: 340000000 RMSE: 1.0524979085866004\n",
      "Epoch: 341000000 RMSE: 1.052384068549888\n",
      "Epoch: 342000000 RMSE: 1.0522645792214198\n",
      "Epoch: 343000000 RMSE: 1.0521609378216246\n",
      "Epoch: 344000000 RMSE: 1.052038277447726\n",
      "Epoch: 345000000 RMSE: 1.0519361257588704\n",
      "Epoch: 346000000 RMSE: 1.0518293204803462\n",
      "Epoch: 347000000 RMSE: 1.051720545190807\n",
      "Epoch: 348000000 RMSE: 1.0516155991415854\n",
      "Epoch: 349000000 RMSE: 1.0515401157515338\n",
      "Epoch: 350000000 RMSE: 1.0514329074434865\n",
      "Epoch: 351000000 RMSE: 1.051333015772092\n",
      "Epoch: 352000000 RMSE: 1.0512092687130425\n",
      "Epoch: 353000000 RMSE: 1.0510949750329548\n",
      "Epoch: 354000000 RMSE: 1.051008630391705\n",
      "Epoch: 355000000 RMSE: 1.0509231877939438\n",
      "Epoch: 356000000 RMSE: 1.0508264687449367\n",
      "Epoch: 357000000 RMSE: 1.0507363298115913\n",
      "Epoch: 358000000 RMSE: 1.0506464952882661\n",
      "Epoch: 359000000 RMSE: 1.0505652475295821\n",
      "Epoch: 360000000 RMSE: 1.0504668194669349\n",
      "Epoch: 361000000 RMSE: 1.050370657609196\n",
      "Epoch: 362000000 RMSE: 1.0502581174714591\n",
      "Epoch: 363000000 RMSE: 1.0501521679169088\n",
      "Epoch: 364000000 RMSE: 1.0500649479400357\n",
      "Epoch: 365000000 RMSE: 1.049962667318151\n",
      "Epoch: 366000000 RMSE: 1.0498807759730662\n",
      "Epoch: 367000000 RMSE: 1.0498024707354339\n",
      "Epoch: 368000000 RMSE: 1.049689906099299\n",
      "Epoch: 369000000 RMSE: 1.0495908107195022\n",
      "Epoch: 370000000 RMSE: 1.0494821485285524\n",
      "Epoch: 371000000 RMSE: 1.0493953885197924\n",
      "Epoch: 372000000 RMSE: 1.0492928343956784\n",
      "Epoch: 373000000 RMSE: 1.0491812530097329\n",
      "Epoch: 374000000 RMSE: 1.0490830650135068\n",
      "Epoch: 375000000 RMSE: 1.048994086291897\n",
      "Epoch: 376000000 RMSE: 1.048920323473453\n",
      "Epoch: 377000000 RMSE: 1.0488491376972418\n",
      "Epoch: 378000000 RMSE: 1.0487819988247835\n",
      "Epoch: 379000000 RMSE: 1.0486978047579414\n",
      "Epoch: 380000000 RMSE: 1.048607598254103\n",
      "Epoch: 381000000 RMSE: 1.0485149351538496\n",
      "Epoch: 382000000 RMSE: 1.0484300785442324\n",
      "Epoch: 383000000 RMSE: 1.0483509469288077\n",
      "Epoch: 384000000 RMSE: 1.0482704449294753\n",
      "Epoch: 385000000 RMSE: 1.0481854566610338\n",
      "Epoch: 386000000 RMSE: 1.048096639107603\n",
      "Epoch: 387000000 RMSE: 1.0480214605368476\n",
      "Epoch: 388000000 RMSE: 1.0479271936801449\n",
      "Epoch: 389000000 RMSE: 1.047845759921213\n",
      "Epoch: 390000000 RMSE: 1.047738274604158\n",
      "Epoch: 391000000 RMSE: 1.047651838901413\n",
      "Epoch: 392000000 RMSE: 1.047565299966603\n",
      "Epoch: 393000000 RMSE: 1.0474769412494591\n",
      "Epoch: 394000000 RMSE: 1.0473888244242724\n",
      "Epoch: 395000000 RMSE: 1.0473135581650281\n",
      "Epoch: 396000000 RMSE: 1.0472099055231574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 397000000 RMSE: 1.047144745769689\n",
      "Epoch: 398000000 RMSE: 1.0470700010206564\n",
      "Epoch: 399000000 RMSE: 1.0469934143814128\n",
      "Epoch: 400000000 RMSE: 1.0469313970404504\n",
      "Epoch: 401000000 RMSE: 1.0468708162519065\n",
      "Epoch: 402000000 RMSE: 1.046781119545531\n",
      "Epoch: 403000000 RMSE: 1.0467087487685776\n",
      "Epoch: 404000000 RMSE: 1.0466587438951618\n",
      "Epoch: 405000000 RMSE: 1.0465826285930577\n",
      "Epoch: 406000000 RMSE: 1.0464981125563027\n",
      "Epoch: 407000000 RMSE: 1.046424604775315\n",
      "Epoch: 408000000 RMSE: 1.0463558406141666\n",
      "Epoch: 409000000 RMSE: 1.046263928234367\n",
      "Epoch: 410000000 RMSE: 1.0461772574414305\n",
      "Epoch: 411000000 RMSE: 1.0460825399194356\n",
      "Epoch: 412000000 RMSE: 1.0459994674262394\n",
      "Epoch: 413000000 RMSE: 1.045950150332658\n",
      "Epoch: 414000000 RMSE: 1.0458860281624167\n",
      "Epoch: 415000000 RMSE: 1.045793162009117\n",
      "Epoch: 416000000 RMSE: 1.0457058550196412\n",
      "Epoch: 417000000 RMSE: 1.0456702321655678\n",
      "Epoch: 418000000 RMSE: 1.0456105705864573\n",
      "Epoch: 419000000 RMSE: 1.0455607432576814\n",
      "Epoch: 420000000 RMSE: 1.0454978992362267\n",
      "Epoch: 421000000 RMSE: 1.0454247899389604\n",
      "Epoch: 422000000 RMSE: 1.0453576326067333\n",
      "Epoch: 423000000 RMSE: 1.045292465873182\n",
      "Epoch: 424000000 RMSE: 1.045227393446308\n",
      "Epoch: 425000000 RMSE: 1.0451385144431546\n",
      "Epoch: 426000000 RMSE: 1.0450603539914027\n",
      "Epoch: 427000000 RMSE: 1.0449798555991754\n",
      "Epoch: 428000000 RMSE: 1.0449075419856868\n",
      "Epoch: 429000000 RMSE: 1.044866663980843\n",
      "Epoch: 430000000 RMSE: 1.0447999962924848\n",
      "Epoch: 431000000 RMSE: 1.0447322833481285\n",
      "Epoch: 432000000 RMSE: 1.0446757597442224\n",
      "Epoch: 433000000 RMSE: 1.0446107945200658\n",
      "Epoch: 434000000 RMSE: 1.0445550921721594\n",
      "Epoch: 435000000 RMSE: 1.044499422308347\n",
      "Epoch: 436000000 RMSE: 1.044430917723399\n",
      "Epoch: 437000000 RMSE: 1.0443696409261072\n",
      "Epoch: 438000000 RMSE: 1.0443307608598238\n",
      "Epoch: 439000000 RMSE: 1.0442675048824366\n",
      "Epoch: 440000000 RMSE: 1.0442204581480388\n",
      "Epoch: 441000000 RMSE: 1.0441591727640005\n",
      "Epoch: 442000000 RMSE: 1.0440934552310426\n",
      "Epoch: 443000000 RMSE: 1.0440331340853242\n",
      "Epoch: 444000000 RMSE: 1.0439709340651175\n",
      "Epoch: 445000000 RMSE: 1.043906256305485\n",
      "Epoch: 446000000 RMSE: 1.0438230624674991\n",
      "Epoch: 447000000 RMSE: 1.043744173973854\n",
      "Epoch: 448000000 RMSE: 1.043675783261763\n",
      "Epoch: 449000000 RMSE: 1.0436342008897639\n",
      "Epoch: 450000000 RMSE: 1.0435721556850153\n",
      "Epoch: 451000000 RMSE: 1.0435011393289257\n",
      "Epoch: 452000000 RMSE: 1.0434597891251296\n",
      "Epoch: 453000000 RMSE: 1.04340969035579\n",
      "Epoch: 454000000 RMSE: 1.043350555432748\n",
      "Epoch: 455000000 RMSE: 1.043287704894286\n",
      "Epoch: 456000000 RMSE: 1.043202931836147\n",
      "Epoch: 457000000 RMSE: 1.043145944124967\n",
      "Epoch: 458000000 RMSE: 1.043076316332902\n",
      "Epoch: 459000000 RMSE: 1.043010207602237\n",
      "Epoch: 460000000 RMSE: 1.0429535147931481\n",
      "Epoch: 461000000 RMSE: 1.0429049797960244\n",
      "Epoch: 462000000 RMSE: 1.042880544698214\n",
      "Epoch: 463000000 RMSE: 1.0428216637252814\n",
      "Epoch: 464000000 RMSE: 1.0427872712698587\n",
      "Epoch: 465000000 RMSE: 1.0427309636079305\n",
      "Epoch: 466000000 RMSE: 1.0426653265421841\n",
      "Epoch: 467000000 RMSE: 1.0426121413999994\n",
      "Epoch: 468000000 RMSE: 1.0425511245182377\n",
      "Epoch: 469000000 RMSE: 1.042511175660833\n",
      "Epoch: 470000000 RMSE: 1.0424736982071516\n",
      "Epoch: 471000000 RMSE: 1.0424227414206397\n",
      "Epoch: 472000000 RMSE: 1.0423570678711624\n",
      "Epoch: 473000000 RMSE: 1.0423003147043888\n",
      "Epoch: 474000000 RMSE: 1.0422306624350475\n",
      "Epoch: 475000000 RMSE: 1.0421883361352777\n",
      "Epoch: 476000000 RMSE: 1.0421554769420889\n",
      "Epoch: 477000000 RMSE: 1.0421098825881612\n",
      "Epoch: 478000000 RMSE: 1.0420569923071066\n",
      "Epoch: 479000000 RMSE: 1.0419958907438822\n",
      "Epoch: 480000000 RMSE: 1.0419353438405559\n",
      "Epoch: 481000000 RMSE: 1.0418790183677895\n",
      "Epoch: 482000000 RMSE: 1.0418168441695905\n",
      "Epoch: 483000000 RMSE: 1.0417666760440867\n",
      "Epoch: 484000000 RMSE: 1.0417227702937804\n",
      "Epoch: 485000000 RMSE: 1.041653865771125\n",
      "Epoch: 486000000 RMSE: 1.0416004220101098\n",
      "Epoch: 487000000 RMSE: 1.0415469676051043\n",
      "Epoch: 488000000 RMSE: 1.0414991119650758\n",
      "Epoch: 489000000 RMSE: 1.0414542704548475\n",
      "Epoch: 490000000 RMSE: 1.0413949260249074\n",
      "Epoch: 491000000 RMSE: 1.041353085977316\n",
      "Epoch: 492000000 RMSE: 1.0412862071451519\n",
      "Epoch: 493000000 RMSE: 1.0412219782897991\n",
      "Epoch: 494000000 RMSE: 1.0411770601323445\n",
      "Epoch: 495000000 RMSE: 1.0411447937517446\n",
      "Epoch: 496000000 RMSE: 1.0410977131155155\n",
      "Epoch: 497000000 RMSE: 1.0410482654601556\n",
      "Epoch: 498000000 RMSE: 1.0409957335059916\n",
      "Epoch: 499000000 RMSE: 1.0409281788776337\n",
      "Epoch: 500000000 RMSE: 1.0408824846006193\n",
      "Epoch: 501000000 RMSE: 1.0408316829014728\n",
      "Epoch: 502000000 RMSE: 1.0407773405394927\n",
      "Epoch: 503000000 RMSE: 1.0407460150622334\n",
      "Epoch: 504000000 RMSE: 1.0406997617055591\n",
      "Epoch: 505000000 RMSE: 1.0406615960857384\n",
      "Epoch: 506000000 RMSE: 1.0406148498500645\n",
      "Epoch: 507000000 RMSE: 1.0405558528506222\n",
      "Epoch: 508000000 RMSE: 1.0405055612583245\n",
      "Epoch: 509000000 RMSE: 1.0404641374512469\n",
      "Epoch: 510000000 RMSE: 1.0404203937842327\n",
      "Epoch: 511000000 RMSE: 1.0403742027407379\n",
      "Epoch: 512000000 RMSE: 1.0403216208527621\n",
      "Epoch: 513000000 RMSE: 1.0402620664126319\n",
      "Epoch: 514000000 RMSE: 1.0402318650588176\n",
      "Epoch: 515000000 RMSE: 1.040213966632131\n",
      "Epoch: 516000000 RMSE: 1.0401628387553652\n",
      "Epoch: 517000000 RMSE: 1.0401056448891093\n",
      "Epoch: 518000000 RMSE: 1.0400626266862039\n",
      "Epoch: 519000000 RMSE: 1.0400371697475328\n",
      "Epoch: 520000000 RMSE: 1.0399706649179097\n",
      "Epoch: 521000000 RMSE: 1.039924572184151\n",
      "Epoch: 522000000 RMSE: 1.0398752655413033\n",
      "Epoch: 523000000 RMSE: 1.0398646771073385\n",
      "Epoch: 524000000 RMSE: 1.0397945481396484\n",
      "Epoch: 525000000 RMSE: 1.0397680112046026\n",
      "Epoch: 526000000 RMSE: 1.039703589115857\n",
      "Epoch: 527000000 RMSE: 1.0396669656081357\n",
      "Epoch: 528000000 RMSE: 1.0396258950862756\n",
      "Epoch: 529000000 RMSE: 1.0395688831927088\n",
      "Epoch: 530000000 RMSE: 1.039524925046915\n",
      "Epoch: 531000000 RMSE: 1.0394868088037603\n",
      "Epoch: 532000000 RMSE: 1.0394603644053715\n",
      "Epoch: 533000000 RMSE: 1.0394156754700945\n",
      "Epoch: 534000000 RMSE: 1.0393797970524026\n",
      "Epoch: 535000000 RMSE: 1.03932920168221\n",
      "Epoch: 536000000 RMSE: 1.0392792544985217\n",
      "Epoch: 537000000 RMSE: 1.0392212582628664\n",
      "Epoch: 538000000 RMSE: 1.0391888147882018\n",
      "Epoch: 539000000 RMSE: 1.0391400133053394\n",
      "Epoch: 540000000 RMSE: 1.0390990269495923\n",
      "Epoch: 541000000 RMSE: 1.0390602003587528\n",
      "Epoch: 542000000 RMSE: 1.0390211294958038\n",
      "Epoch: 543000000 RMSE: 1.0390026322150745\n",
      "Epoch: 544000000 RMSE: 1.0389541507436473\n",
      "Epoch: 545000000 RMSE: 1.0389151817252191\n",
      "Epoch: 546000000 RMSE: 1.0388748081661796\n",
      "Epoch: 547000000 RMSE: 1.0388179855532986\n",
      "Epoch: 548000000 RMSE: 1.038774976790907\n",
      "Epoch: 549000000 RMSE: 1.0387614190210157\n",
      "Epoch: 550000000 RMSE: 1.038747000072835\n",
      "Epoch: 551000000 RMSE: 1.0386905022399338\n",
      "Epoch: 552000000 RMSE: 1.0386696042314434\n",
      "Epoch: 553000000 RMSE: 1.038605233813008\n",
      "Epoch: 554000000 RMSE: 1.0385585816605059\n",
      "Epoch: 555000000 RMSE: 1.0385271782660923\n",
      "Epoch: 556000000 RMSE: 1.0384883569576135\n",
      "Epoch: 557000000 RMSE: 1.038455950548699\n",
      "Epoch: 558000000 RMSE: 1.0384187065668622\n",
      "Epoch: 559000000 RMSE: 1.0383696242889808\n",
      "Epoch: 560000000 RMSE: 1.0383331678685228\n",
      "Epoch: 561000000 RMSE: 1.038278385818432\n",
      "Epoch: 562000000 RMSE: 1.0382379716287073\n",
      "Epoch: 563000000 RMSE: 1.0382027707113264\n",
      "Epoch: 564000000 RMSE: 1.0381628394263422\n",
      "Epoch: 565000000 RMSE: 1.0381202845968887\n",
      "Epoch: 566000000 RMSE: 1.0380805183391777\n",
      "Epoch: 567000000 RMSE: 1.038051129046181\n",
      "Epoch: 568000000 RMSE: 1.0380157697810122\n",
      "Epoch: 569000000 RMSE: 1.0379977169953607\n",
      "Epoch: 570000000 RMSE: 1.0379812480552808\n",
      "Epoch: 571000000 RMSE: 1.037942406274485\n",
      "Epoch: 572000000 RMSE: 1.0379101051226607\n",
      "Epoch: 573000000 RMSE: 1.037890072754969\n",
      "Epoch: 574000000 RMSE: 1.037837911514887\n",
      "Epoch: 575000000 RMSE: 1.0378173429718662\n",
      "Epoch: 576000000 RMSE: 1.037789504970553\n",
      "Epoch: 577000000 RMSE: 1.0377556381127755\n",
      "Epoch: 578000000 RMSE: 1.0377166082043947\n",
      "Epoch: 579000000 RMSE: 1.0376625422278507\n",
      "Epoch: 580000000 RMSE: 1.0376338366671853\n",
      "Epoch: 581000000 RMSE: 1.0376157045627978\n",
      "Epoch: 582000000 RMSE: 1.0375650022928233\n",
      "Epoch: 583000000 RMSE: 1.0375236789281297\n",
      "Epoch: 584000000 RMSE: 1.0375030779385648\n",
      "Epoch: 585000000 RMSE: 1.0374822274930202\n",
      "Epoch: 586000000 RMSE: 1.0374641830075586\n",
      "Epoch: 587000000 RMSE: 1.0374388007006354\n",
      "Epoch: 588000000 RMSE: 1.0374014600789057\n",
      "Epoch: 589000000 RMSE: 1.0373768376623125\n",
      "Epoch: 590000000 RMSE: 1.0373276929750594\n",
      "Epoch: 591000000 RMSE: 1.0373138378150715\n",
      "Epoch: 592000000 RMSE: 1.037289333460044\n",
      "Epoch: 593000000 RMSE: 1.0372506708468654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 594000000 RMSE: 1.0371856046357246\n",
      "Epoch: 595000000 RMSE: 1.0371628109492799\n",
      "Epoch: 596000000 RMSE: 1.0371192006784522\n",
      "Epoch: 597000000 RMSE: 1.0370772235835977\n",
      "Epoch: 598000000 RMSE: 1.0370260331287475\n",
      "Epoch: 599000000 RMSE: 1.0369812818071882\n",
      "Epoch: 600000000 RMSE: 1.0369577691107086\n",
      "Epoch: 601000000 RMSE: 1.0369176998977974\n",
      "Epoch: 602000000 RMSE: 1.036893424772928\n",
      "Epoch: 603000000 RMSE: 1.0368513323916193\n",
      "Epoch: 604000000 RMSE: 1.0368136562383024\n",
      "Epoch: 605000000 RMSE: 1.0367935400899755\n",
      "Epoch: 606000000 RMSE: 1.0367666898078285\n",
      "Epoch: 607000000 RMSE: 1.0367448394514827\n",
      "Epoch: 608000000 RMSE: 1.0367303602196551\n",
      "Epoch: 609000000 RMSE: 1.0366660685685185\n",
      "Epoch: 610000000 RMSE: 1.0366371397756087\n",
      "Epoch: 611000000 RMSE: 1.036611497140289\n",
      "Epoch: 612000000 RMSE: 1.0365752868716325\n",
      "Epoch: 613000000 RMSE: 1.0365449053608562\n",
      "Epoch: 614000000 RMSE: 1.0365220757767295\n",
      "Epoch: 615000000 RMSE: 1.0364689546996035\n",
      "Epoch: 616000000 RMSE: 1.0364404541308758\n",
      "Epoch: 617000000 RMSE: 1.036421928554196\n",
      "Epoch: 618000000 RMSE: 1.0363873278877018\n",
      "Epoch: 619000000 RMSE: 1.0363726406755944\n",
      "Epoch: 620000000 RMSE: 1.0363551245790426\n",
      "Epoch: 621000000 RMSE: 1.0363233328918442\n",
      "Epoch: 622000000 RMSE: 1.036307160590959\n",
      "Epoch: 623000000 RMSE: 1.0362828758217635\n",
      "Epoch: 624000000 RMSE: 1.036255233495516\n",
      "Epoch: 625000000 RMSE: 1.0362006834975166\n",
      "Epoch: 626000000 RMSE: 1.0361620483849192\n",
      "Epoch: 627000000 RMSE: 1.0361484692741847\n",
      "Epoch: 628000000 RMSE: 1.0361080069290554\n",
      "Epoch: 629000000 RMSE: 1.0360888229915206\n",
      "Epoch: 630000000 RMSE: 1.0360748090432892\n",
      "Epoch: 631000000 RMSE: 1.0360418938624574\n",
      "Epoch: 632000000 RMSE: 1.0360202763944586\n",
      "Epoch: 633000000 RMSE: 1.0359864210808023\n",
      "Epoch: 634000000 RMSE: 1.035952983070151\n",
      "Epoch: 635000000 RMSE: 1.0359323647157614\n",
      "Epoch: 636000000 RMSE: 1.0359160580939246\n",
      "Epoch: 637000000 RMSE: 1.0358855724574854\n",
      "Epoch: 638000000 RMSE: 1.0358408740095497\n",
      "Epoch: 639000000 RMSE: 1.035807151757443\n",
      "Epoch: 640000000 RMSE: 1.0358136607355255\n",
      "Epoch: 641000000 RMSE: 1.035782379162187\n",
      "Epoch: 642000000 RMSE: 1.035732590218248\n",
      "Epoch: 643000000 RMSE: 1.0357132248288567\n",
      "Epoch: 644000000 RMSE: 1.035682210892747\n",
      "Epoch: 645000000 RMSE: 1.0356504296068836\n",
      "Epoch: 646000000 RMSE: 1.0356347311416318\n",
      "Epoch: 647000000 RMSE: 1.035626960839432\n",
      "Epoch: 648000000 RMSE: 1.035601373137242\n",
      "Epoch: 649000000 RMSE: 1.0355865079781326\n",
      "Epoch: 650000000 RMSE: 1.0355572629712566\n",
      "Epoch: 651000000 RMSE: 1.035521724389625\n",
      "Epoch: 652000000 RMSE: 1.0355066009630263\n",
      "Epoch: 653000000 RMSE: 1.0354594054152035\n",
      "Epoch: 654000000 RMSE: 1.0354474052350018\n",
      "Epoch: 655000000 RMSE: 1.0354345362744632\n",
      "Epoch: 656000000 RMSE: 1.0353979155027895\n",
      "Epoch: 657000000 RMSE: 1.0353600142832335\n",
      "Epoch: 658000000 RMSE: 1.0353485644284406\n",
      "Epoch: 659000000 RMSE: 1.0353345817876098\n",
      "Epoch: 660000000 RMSE: 1.0352996501110805\n",
      "Epoch: 661000000 RMSE: 1.0352554213933653\n",
      "Epoch: 662000000 RMSE: 1.0352264600121672\n",
      "Epoch: 663000000 RMSE: 1.0351816020973856\n",
      "Epoch: 664000000 RMSE: 1.035151761538984\n",
      "Epoch: 665000000 RMSE: 1.0351274018771601\n",
      "Epoch: 666000000 RMSE: 1.035115087838565\n",
      "Epoch: 667000000 RMSE: 1.0350797358591437\n",
      "Epoch: 668000000 RMSE: 1.0350470985816496\n",
      "Epoch: 669000000 RMSE: 1.0350184124109283\n",
      "Epoch: 670000000 RMSE: 1.0349841756713818\n",
      "Epoch: 671000000 RMSE: 1.034963317674036\n",
      "Epoch: 672000000 RMSE: 1.0349296478073606\n",
      "Epoch: 673000000 RMSE: 1.0349234325532815\n",
      "Epoch: 674000000 RMSE: 1.034893069629643\n",
      "Epoch: 675000000 RMSE: 1.034888622993561\n",
      "Epoch: 676000000 RMSE: 1.0348611172118503\n",
      "Epoch: 677000000 RMSE: 1.034844575310321\n",
      "Epoch: 678000000 RMSE: 1.0348090380949189\n",
      "Epoch: 679000000 RMSE: 1.0347744100106808\n",
      "Epoch: 680000000 RMSE: 1.0347596299553434\n",
      "Epoch: 681000000 RMSE: 1.0347355472324875\n",
      "Epoch: 682000000 RMSE: 1.034720721576788\n",
      "Epoch: 683000000 RMSE: 1.0346773040668669\n",
      "Epoch: 684000000 RMSE: 1.0346351096837123\n",
      "Epoch: 685000000 RMSE: 1.0346121367564063\n",
      "Epoch: 686000000 RMSE: 1.0345873135950887\n",
      "Epoch: 687000000 RMSE: 1.034571489312891\n",
      "Epoch: 688000000 RMSE: 1.0345495239678306\n",
      "Epoch: 689000000 RMSE: 1.0345274913059959\n",
      "Epoch: 690000000 RMSE: 1.0344964332349265\n",
      "Epoch: 691000000 RMSE: 1.0344717860447166\n",
      "Epoch: 692000000 RMSE: 1.0344461287277846\n",
      "Epoch: 693000000 RMSE: 1.0344371068747908\n",
      "Epoch: 694000000 RMSE: 1.0344290312878912\n",
      "Epoch: 695000000 RMSE: 1.0343931425357238\n",
      "Epoch: 696000000 RMSE: 1.0343779327290956\n",
      "Epoch: 697000000 RMSE: 1.0343771776177122\n",
      "Epoch: 698000000 RMSE: 1.0343489456662103\n",
      "Epoch: 699000000 RMSE: 1.0343212107061326\n",
      "Epoch: 700000000 RMSE: 1.0342977343573427\n",
      "Epoch: 701000000 RMSE: 1.034257325486452\n",
      "Epoch: 702000000 RMSE: 1.0342592168189024\n",
      "Epoch: 703000000 RMSE: 1.0342108017391787\n",
      "Epoch: 704000000 RMSE: 1.0341829290996363\n",
      "Epoch: 705000000 RMSE: 1.034155548565654\n",
      "Epoch: 706000000 RMSE: 1.0341426542495622\n",
      "Epoch: 707000000 RMSE: 1.03414117116147\n",
      "Epoch: 708000000 RMSE: 1.0341137505653335\n",
      "Epoch: 709000000 RMSE: 1.0340877777069135\n",
      "Epoch: 710000000 RMSE: 1.0340453004147954\n",
      "Epoch: 711000000 RMSE: 1.0340254150958026\n",
      "Epoch: 712000000 RMSE: 1.033993613001085\n",
      "Epoch: 713000000 RMSE: 1.0339617493628512\n",
      "Epoch: 714000000 RMSE: 1.033946098965759\n",
      "Epoch: 715000000 RMSE: 1.0339355853870635\n",
      "Epoch: 716000000 RMSE: 1.03393770494547\n",
      "Epoch: 717000000 RMSE: 1.0339188133553399\n",
      "Epoch: 718000000 RMSE: 1.0338967074370262\n",
      "Epoch: 719000000 RMSE: 1.033866409133954\n",
      "Epoch: 720000000 RMSE: 1.0338450597614393\n",
      "Epoch: 721000000 RMSE: 1.033822361070772\n",
      "Epoch: 722000000 RMSE: 1.0337899586320718\n",
      "Epoch: 723000000 RMSE: 1.0337770590644408\n",
      "Epoch: 724000000 RMSE: 1.0337564289287593\n",
      "Epoch: 725000000 RMSE: 1.0337441993956504\n",
      "Epoch: 726000000 RMSE: 1.033737274658489\n",
      "Epoch: 727000000 RMSE: 1.0337105245453626\n",
      "Epoch: 728000000 RMSE: 1.0336892313154622\n",
      "Epoch: 729000000 RMSE: 1.0336582859354022\n",
      "Epoch: 730000000 RMSE: 1.0336335895672653\n",
      "Epoch: 731000000 RMSE: 1.033617691871433\n",
      "Epoch: 732000000 RMSE: 1.0335963264977936\n",
      "Epoch: 733000000 RMSE: 1.03357275563192\n",
      "Epoch: 734000000 RMSE: 1.0335551442647675\n",
      "Epoch: 735000000 RMSE: 1.0335117689115536\n",
      "Epoch: 736000000 RMSE: 1.033501500976317\n",
      "Epoch: 737000000 RMSE: 1.0334772811089317\n",
      "Epoch: 738000000 RMSE: 1.0334511089115788\n",
      "Epoch: 739000000 RMSE: 1.0334218710134746\n",
      "Epoch: 740000000 RMSE: 1.0333976516370136\n",
      "Epoch: 741000000 RMSE: 1.0333635951639502\n",
      "Epoch: 742000000 RMSE: 1.0333358736584766\n",
      "Epoch: 743000000 RMSE: 1.03330891297799\n",
      "Epoch: 744000000 RMSE: 1.033286393802386\n",
      "Epoch: 745000000 RMSE: 1.0332807949156144\n",
      "Epoch: 746000000 RMSE: 1.0332564677911367\n",
      "Epoch: 747000000 RMSE: 1.0332202606592422\n",
      "Epoch: 748000000 RMSE: 1.0332171353081165\n",
      "Epoch: 749000000 RMSE: 1.0332092320739235\n",
      "Epoch: 750000000 RMSE: 1.0332038312474792\n",
      "Epoch: 751000000 RMSE: 1.0331737517106352\n",
      "Epoch: 752000000 RMSE: 1.0331710668690677\n",
      "Epoch: 753000000 RMSE: 1.0331593839040498\n",
      "Epoch: 754000000 RMSE: 1.0331414247476638\n",
      "Epoch: 755000000 RMSE: 1.033135779572514\n",
      "Epoch: 756000000 RMSE: 1.0331058836376508\n",
      "Epoch: 757000000 RMSE: 1.0330862572443773\n",
      "Epoch: 758000000 RMSE: 1.0330853043280452\n",
      "Epoch: 759000000 RMSE: 1.0330658267164228\n",
      "Epoch: 760000000 RMSE: 1.033048000405368\n",
      "Epoch: 761000000 RMSE: 1.033029762885723\n",
      "Epoch: 762000000 RMSE: 1.033020818519499\n",
      "Epoch: 763000000 RMSE: 1.032975840844966\n",
      "Epoch: 764000000 RMSE: 1.0329450871795105\n",
      "Epoch: 765000000 RMSE: 1.0329203852143702\n",
      "Epoch: 766000000 RMSE: 1.0329043284427903\n",
      "Epoch: 767000000 RMSE: 1.0329005973314334\n",
      "Epoch: 768000000 RMSE: 1.0328900724642673\n",
      "Epoch: 769000000 RMSE: 1.0328632552318462\n",
      "Epoch: 770000000 RMSE: 1.0328298282162962\n",
      "Epoch: 771000000 RMSE: 1.0328223972965527\n",
      "Epoch: 772000000 RMSE: 1.0328011921169502\n",
      "Epoch: 773000000 RMSE: 1.032780065392221\n",
      "Epoch: 774000000 RMSE: 1.0327795488139235\n",
      "Epoch: 775000000 RMSE: 1.032767848259692\n",
      "Epoch: 776000000 RMSE: 1.0327508122804356\n",
      "Epoch: 777000000 RMSE: 1.0327340385302317\n",
      "Epoch: 778000000 RMSE: 1.0327353977150953\n",
      "Epoch: 779000000 RMSE: 1.032724602299337\n",
      "Epoch: 780000000 RMSE: 1.032706650539229\n",
      "Epoch: 781000000 RMSE: 1.0327098758187556\n",
      "Epoch: 782000000 RMSE: 1.0326979576884683\n",
      "Epoch: 783000000 RMSE: 1.0326624603970977\n",
      "Epoch: 784000000 RMSE: 1.032655939294365\n",
      "Epoch: 785000000 RMSE: 1.0326476818608985\n",
      "Epoch: 786000000 RMSE: 1.032629474929998\n",
      "Epoch: 787000000 RMSE: 1.0326058234384423\n",
      "Epoch: 788000000 RMSE: 1.032584681956045\n",
      "Epoch: 789000000 RMSE: 1.032568646400368\n",
      "Epoch: 790000000 RMSE: 1.0325637302313624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 791000000 RMSE: 1.0325470876042535\n",
      "Epoch: 792000000 RMSE: 1.0325316501254207\n",
      "Epoch: 793000000 RMSE: 1.0325114823599826\n",
      "Epoch: 794000000 RMSE: 1.0324768842251815\n",
      "Epoch: 795000000 RMSE: 1.0324553579901472\n",
      "Epoch: 796000000 RMSE: 1.0324299541344395\n",
      "Epoch: 797000000 RMSE: 1.0324086109640376\n",
      "Epoch: 798000000 RMSE: 1.0323946578682943\n",
      "Epoch: 799000000 RMSE: 1.0323607572493423\n",
      "Epoch: 800000000 RMSE: 1.032338210507691\n",
      "Epoch: 801000000 RMSE: 1.0323267238551495\n",
      "Epoch: 802000000 RMSE: 1.032303858084374\n",
      "Epoch: 803000000 RMSE: 1.0322809432618352\n",
      "Epoch: 804000000 RMSE: 1.032289933466644\n",
      "Epoch: 805000000 RMSE: 1.0322705970744182\n",
      "Epoch: 806000000 RMSE: 1.0322585120763885\n",
      "Epoch: 807000000 RMSE: 1.032262295338257\n",
      "Epoch: 808000000 RMSE: 1.0322624787277415\n",
      "Epoch: 809000000 RMSE: 1.0322416033440631\n",
      "Epoch: 810000000 RMSE: 1.0322163421462212\n",
      "Epoch: 811000000 RMSE: 1.0322093172895064\n",
      "Epoch: 812000000 RMSE: 1.0321849368446168\n",
      "Epoch: 813000000 RMSE: 1.0321719852289633\n",
      "Epoch: 814000000 RMSE: 1.0321545412425108\n",
      "Epoch: 815000000 RMSE: 1.032135193254084\n",
      "Epoch: 816000000 RMSE: 1.0321210092924893\n",
      "Epoch: 817000000 RMSE: 1.0321103789469779\n",
      "Epoch: 818000000 RMSE: 1.03211226647588\n",
      "Epoch: 819000000 RMSE: 1.0320983822359904\n",
      "Epoch: 820000000 RMSE: 1.0320802663042332\n",
      "Epoch: 821000000 RMSE: 1.0320687456898194\n",
      "Epoch: 822000000 RMSE: 1.0320308911637819\n",
      "Epoch: 823000000 RMSE: 1.0320110840722614\n",
      "Epoch: 824000000 RMSE: 1.0319875137742427\n",
      "Epoch: 825000000 RMSE: 1.0319899700753346\n",
      "Epoch: 826000000 RMSE: 1.0319649456370608\n",
      "Epoch: 827000000 RMSE: 1.031959259080006\n",
      "Epoch: 828000000 RMSE: 1.0319325691470722\n",
      "Epoch: 829000000 RMSE: 1.0319165273092592\n",
      "Epoch: 830000000 RMSE: 1.0318964583037455\n",
      "Epoch: 831000000 RMSE: 1.0318764528985653\n",
      "Epoch: 832000000 RMSE: 1.031867963422421\n",
      "Epoch: 833000000 RMSE: 1.031872334084101\n",
      "Epoch: 834000000 RMSE: 1.0318522518772997\n",
      "Epoch: 835000000 RMSE: 1.0318391563520866\n",
      "Epoch: 836000000 RMSE: 1.0318314072681563\n",
      "Epoch: 837000000 RMSE: 1.031822946844769\n",
      "Epoch: 838000000 RMSE: 1.0317872646123043\n",
      "Epoch: 839000000 RMSE: 1.0317656850759778\n",
      "Epoch: 840000000 RMSE: 1.031739973007943\n",
      "Epoch: 841000000 RMSE: 1.0317260921057263\n",
      "Epoch: 842000000 RMSE: 1.0317090058036225\n",
      "Epoch: 843000000 RMSE: 1.0316858727519038\n",
      "Epoch: 844000000 RMSE: 1.0316968487080165\n",
      "Epoch: 845000000 RMSE: 1.0316706247500032\n",
      "Epoch: 846000000 RMSE: 1.0316658225185886\n",
      "Epoch: 847000000 RMSE: 1.0316444398714975\n",
      "Epoch: 848000000 RMSE: 1.0316426035596975\n",
      "Epoch: 849000000 RMSE: 1.031631601910486\n",
      "Epoch: 850000000 RMSE: 1.0316108588437078\n",
      "Epoch: 851000000 RMSE: 1.031598378694168\n",
      "Epoch: 852000000 RMSE: 1.0315940800349148\n",
      "Epoch: 853000000 RMSE: 1.0315701068022907\n",
      "Epoch: 854000000 RMSE: 1.0315718295925378\n",
      "Epoch: 855000000 RMSE: 1.0315426168946984\n",
      "Epoch: 856000000 RMSE: 1.031540272617338\n",
      "Epoch: 857000000 RMSE: 1.0315136287023492\n",
      "Epoch: 858000000 RMSE: 1.0315042080320007\n",
      "Epoch: 859000000 RMSE: 1.0314837716367011\n",
      "Epoch: 860000000 RMSE: 1.0314624972771835\n",
      "Epoch: 861000000 RMSE: 1.0314762284129084\n",
      "Epoch: 862000000 RMSE: 1.03146655187269\n",
      "Epoch: 863000000 RMSE: 1.0314632506954862\n",
      "Epoch: 864000000 RMSE: 1.0314411517007984\n",
      "Epoch: 865000000 RMSE: 1.0314236624010407\n",
      "Epoch: 866000000 RMSE: 1.0314041480101481\n",
      "Epoch: 867000000 RMSE: 1.0314106764073783\n",
      "Epoch: 868000000 RMSE: 1.0313974738386358\n",
      "Epoch: 869000000 RMSE: 1.0313880850857062\n",
      "Epoch: 870000000 RMSE: 1.031373165642796\n",
      "Epoch: 871000000 RMSE: 1.0313614369343609\n",
      "Epoch: 872000000 RMSE: 1.0313486908479461\n",
      "Epoch: 873000000 RMSE: 1.0313447439174408\n",
      "Epoch: 874000000 RMSE: 1.0313495523585843\n",
      "Epoch: 875000000 RMSE: 1.0313391560742216\n",
      "Epoch: 876000000 RMSE: 1.0313298814846055\n",
      "Epoch: 877000000 RMSE: 1.0312972170862933\n",
      "Epoch: 878000000 RMSE: 1.0312987389657131\n",
      "Epoch: 879000000 RMSE: 1.0312777650482752\n",
      "Epoch: 880000000 RMSE: 1.031263031041852\n",
      "Epoch: 881000000 RMSE: 1.0312515694275093\n",
      "Epoch: 882000000 RMSE: 1.0312311766210993\n",
      "Epoch: 883000000 RMSE: 1.0312112205622521\n",
      "Epoch: 884000000 RMSE: 1.0312069113378877\n",
      "Epoch: 885000000 RMSE: 1.0312107969721214\n",
      "Epoch: 886000000 RMSE: 1.0312058336470238\n",
      "Epoch: 887000000 RMSE: 1.0311842622208225\n",
      "Epoch: 888000000 RMSE: 1.0311636076028297\n",
      "Epoch: 889000000 RMSE: 1.0311328533590483\n",
      "Epoch: 890000000 RMSE: 1.0311238769140398\n",
      "Epoch: 891000000 RMSE: 1.0311272369533602\n",
      "Epoch: 892000000 RMSE: 1.0311101333386101\n",
      "Epoch: 893000000 RMSE: 1.0310927183160286\n",
      "Epoch: 894000000 RMSE: 1.031106255339781\n",
      "Epoch: 895000000 RMSE: 1.0310743689774335\n",
      "Epoch: 896000000 RMSE: 1.0310631902738192\n",
      "Epoch: 897000000 RMSE: 1.0310564235564925\n",
      "Epoch: 898000000 RMSE: 1.031054297614066\n",
      "Epoch: 899000000 RMSE: 1.0310432802686216\n",
      "Epoch: 900000000 RMSE: 1.031030036109527\n",
      "Epoch: 901000000 RMSE: 1.0310214503668007\n",
      "Epoch: 902000000 RMSE: 1.0310057464422417\n",
      "Epoch: 903000000 RMSE: 1.0310051894916186\n",
      "Epoch: 904000000 RMSE: 1.0309822370255441\n",
      "Epoch: 905000000 RMSE: 1.0309911785389665\n",
      "Epoch: 906000000 RMSE: 1.0309683549407138\n",
      "Epoch: 907000000 RMSE: 1.0309680621967958\n",
      "Epoch: 908000000 RMSE: 1.0309477010189732\n",
      "Epoch: 909000000 RMSE: 1.0309503139998184\n",
      "Epoch: 910000000 RMSE: 1.030942517716943\n",
      "Epoch: 911000000 RMSE: 1.0309280698369045\n",
      "Epoch: 912000000 RMSE: 1.0309081530580475\n",
      "Epoch: 913000000 RMSE: 1.0308917347705435\n",
      "Epoch: 914000000 RMSE: 1.0308798186472292\n",
      "Epoch: 915000000 RMSE: 1.0308540416234102\n",
      "Epoch: 916000000 RMSE: 1.0308220441941645\n",
      "Epoch: 917000000 RMSE: 1.0308065450392032\n",
      "Epoch: 918000000 RMSE: 1.030802009746844\n",
      "Epoch: 919000000 RMSE: 1.0307900523961646\n",
      "Epoch: 920000000 RMSE: 1.0307753197166545\n",
      "Epoch: 921000000 RMSE: 1.0307495227348529\n",
      "Epoch: 922000000 RMSE: 1.0307237946401013\n",
      "Epoch: 923000000 RMSE: 1.0307075763793312\n",
      "Epoch: 924000000 RMSE: 1.0307187195122487\n",
      "Epoch: 925000000 RMSE: 1.0307207637577704\n",
      "Epoch: 926000000 RMSE: 1.0307193977535458\n",
      "Epoch: 927000000 RMSE: 1.0307507943848044\n",
      "Epoch: 928000000 RMSE: 1.030753707409834\n",
      "Epoch: 929000000 RMSE: 1.0307543346804084\n",
      "Epoch: 930000000 RMSE: 1.0307482267850585\n",
      "Epoch: 931000000 RMSE: 1.0307321649343515\n",
      "Epoch: 932000000 RMSE: 1.0307181547848827\n",
      "Epoch: 933000000 RMSE: 1.0307169579046769\n",
      "Epoch: 934000000 RMSE: 1.0307072699120603\n",
      "Epoch: 935000000 RMSE: 1.0306949736289213\n",
      "Epoch: 936000000 RMSE: 1.030678877345419\n",
      "Epoch: 937000000 RMSE: 1.0306522719137448\n",
      "Epoch: 938000000 RMSE: 1.030629661209169\n",
      "Epoch: 939000000 RMSE: 1.03063071063428\n",
      "Epoch: 940000000 RMSE: 1.0306135828950391\n",
      "Epoch: 941000000 RMSE: 1.0306240243444378\n",
      "Epoch: 942000000 RMSE: 1.0306014071413954\n",
      "Epoch: 943000000 RMSE: 1.0305814818118662\n",
      "Epoch: 944000000 RMSE: 1.030551997520652\n",
      "Epoch: 945000000 RMSE: 1.0305420869544226\n",
      "Epoch: 946000000 RMSE: 1.0305299049969607\n",
      "Epoch: 947000000 RMSE: 1.0305248936940872\n",
      "Epoch: 948000000 RMSE: 1.0304991176738092\n",
      "Epoch: 949000000 RMSE: 1.0304676626156717\n",
      "Epoch: 950000000 RMSE: 1.030479156072815\n",
      "Epoch: 951000000 RMSE: 1.0304733485198863\n",
      "Epoch: 952000000 RMSE: 1.0304565023271\n",
      "Epoch: 953000000 RMSE: 1.0304723676963323\n",
      "Epoch: 954000000 RMSE: 1.030450745328259\n",
      "Epoch: 955000000 RMSE: 1.0304448227103202\n",
      "Epoch: 956000000 RMSE: 1.0304567104929203\n",
      "Epoch: 957000000 RMSE: 1.0304677694303301\n",
      "Epoch: 958000000 RMSE: 1.0304690907685876\n",
      "Epoch: 959000000 RMSE: 1.0304619344569397\n",
      "Epoch: 960000000 RMSE: 1.0304544288577475\n",
      "Epoch: 961000000 RMSE: 1.0304390927773448\n",
      "Epoch: 962000000 RMSE: 1.0304168749183535\n",
      "Epoch: 963000000 RMSE: 1.0303919175788538\n",
      "Epoch: 964000000 RMSE: 1.0303617639192373\n",
      "Epoch: 965000000 RMSE: 1.0303732095160665\n",
      "Epoch: 966000000 RMSE: 1.030368997933557\n",
      "Epoch: 967000000 RMSE: 1.0303552338241928\n",
      "Epoch: 968000000 RMSE: 1.0303531909243502\n",
      "Epoch: 969000000 RMSE: 1.0303237296004601\n",
      "Epoch: 970000000 RMSE: 1.0302975167692854\n",
      "Epoch: 971000000 RMSE: 1.0302877322005937\n",
      "Epoch: 972000000 RMSE: 1.0302957983105834\n",
      "Epoch: 973000000 RMSE: 1.0302863978755104\n",
      "Epoch: 974000000 RMSE: 1.0302668806104547\n",
      "Epoch: 975000000 RMSE: 1.0302570668415736\n",
      "Epoch: 976000000 RMSE: 1.0302556897741422\n",
      "Epoch: 977000000 RMSE: 1.030275065909682\n",
      "Epoch: 978000000 RMSE: 1.0302683346577646\n",
      "Epoch: 979000000 RMSE: 1.0302494927885477\n",
      "Epoch: 980000000 RMSE: 1.0302140341294055\n",
      "Epoch: 981000000 RMSE: 1.0302110743129043\n",
      "Epoch: 982000000 RMSE: 1.0302014811295443\n",
      "Epoch: 983000000 RMSE: 1.0302059984738503\n",
      "Epoch: 984000000 RMSE: 1.030199653964208\n",
      "Epoch: 985000000 RMSE: 1.0301768295931943\n",
      "Epoch: 986000000 RMSE: 1.0301698464317457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 987000000 RMSE: 1.0301519726227129\n",
      "Epoch: 988000000 RMSE: 1.0301455821324665\n",
      "Epoch: 989000000 RMSE: 1.0301311792015186\n",
      "Epoch: 990000000 RMSE: 1.0301124919850526\n",
      "Epoch: 991000000 RMSE: 1.0301079328875697\n",
      "Epoch: 992000000 RMSE: 1.0301181599102789\n",
      "Epoch: 993000000 RMSE: 1.030114678056165\n",
      "Epoch: 994000000 RMSE: 1.0300867812108536\n",
      "Epoch: 995000000 RMSE: 1.0300800726394028\n",
      "Epoch: 996000000 RMSE: 1.0300873074737977\n",
      "Epoch: 997000000 RMSE: 1.030078625263732\n",
      "Epoch: 998000000 RMSE: 1.0300628810428958\n",
      "Epoch: 999000000 RMSE: 1.0300506461424295\n",
      "Epoch: 1000000000 RMSE: 1.0300316011461759\n",
      "Epoch: 1001000000 RMSE: 1.0300118805912877\n",
      "Epoch: 1002000000 RMSE: 1.030005902966834\n",
      "Epoch: 1003000000 RMSE: 1.0299919069603405\n",
      "Epoch: 1004000000 RMSE: 1.0299787439051733\n",
      "Epoch: 1005000000 RMSE: 1.0299760930778104\n",
      "Epoch: 1006000000 RMSE: 1.0299613711301656\n",
      "Epoch: 1007000000 RMSE: 1.0299472414973374\n",
      "Epoch: 1008000000 RMSE: 1.0299383272879932\n",
      "Epoch: 1009000000 RMSE: 1.0299196731958427\n",
      "Epoch: 1010000000 RMSE: 1.0299315924300567\n",
      "Epoch: 1011000000 RMSE: 1.0299398061405953\n",
      "Epoch: 1012000000 RMSE: 1.0299397936937886\n",
      "Epoch: 1013000000 RMSE: 1.0299239790297525\n",
      "Epoch: 1014000000 RMSE: 1.029911030278506\n",
      "Epoch: 1015000000 RMSE: 1.0298918694268444\n",
      "Epoch: 1016000000 RMSE: 1.0298852423133686\n",
      "Epoch: 1017000000 RMSE: 1.0298733863815122\n",
      "Epoch: 1018000000 RMSE: 1.0298823701387607\n",
      "Epoch: 1019000000 RMSE: 1.0298943137776355\n",
      "Epoch: 1020000000 RMSE: 1.0298837944029715\n",
      "Epoch: 1021000000 RMSE: 1.0298685629391668\n",
      "Epoch: 1022000000 RMSE: 1.0298839528189663\n",
      "Epoch: 1023000000 RMSE: 1.0298703303748247\n",
      "Epoch: 1024000000 RMSE: 1.0298526365925227\n",
      "Epoch: 1025000000 RMSE: 1.0298661440893468\n",
      "Epoch: 1026000000 RMSE: 1.0298727619596215\n",
      "Epoch: 1027000000 RMSE: 1.029837890636542\n",
      "Epoch: 1028000000 RMSE: 1.029822285513017\n",
      "Epoch: 1029000000 RMSE: 1.0297963468285436\n",
      "Epoch: 1030000000 RMSE: 1.0297991579178705\n",
      "Epoch: 1031000000 RMSE: 1.0297902148711486\n",
      "Epoch: 1032000000 RMSE: 1.0297709351129962\n",
      "Epoch: 1033000000 RMSE: 1.0297560466591977\n",
      "Epoch: 1034000000 RMSE: 1.029749943476707\n",
      "Epoch: 1035000000 RMSE: 1.029748340961045\n",
      "Epoch: 1036000000 RMSE: 1.0297309997038278\n",
      "Epoch: 1037000000 RMSE: 1.0297223315420074\n",
      "Epoch: 1038000000 RMSE: 1.0297052078945084\n",
      "Epoch: 1039000000 RMSE: 1.0297102743695952\n",
      "Epoch: 1040000000 RMSE: 1.029699515791201\n",
      "Epoch: 1041000000 RMSE: 1.029668262182214\n",
      "Epoch: 1042000000 RMSE: 1.029644975319597\n",
      "Epoch: 1043000000 RMSE: 1.0296302496367398\n",
      "Epoch: 1044000000 RMSE: 1.029616962904\n",
      "Epoch: 1045000000 RMSE: 1.029610797435191\n",
      "Epoch: 1046000000 RMSE: 1.0296075084710656\n",
      "Epoch: 1047000000 RMSE: 1.0295688703353065\n",
      "Epoch: 1048000000 RMSE: 1.0295668504790423\n",
      "Epoch: 1049000000 RMSE: 1.029561460728562\n",
      "Epoch: 1050000000 RMSE: 1.0295439989635953\n",
      "Epoch: 1051000000 RMSE: 1.0295460903026452\n",
      "Epoch: 1052000000 RMSE: 1.0295406245431709\n",
      "Epoch: 1053000000 RMSE: 1.0295545376211825\n",
      "Epoch: 1054000000 RMSE: 1.029553006308231\n",
      "Epoch: 1055000000 RMSE: 1.029537514814676\n",
      "Epoch: 1056000000 RMSE: 1.0295227929473676\n",
      "Epoch: 1057000000 RMSE: 1.0295237246606448\n",
      "Epoch: 1058000000 RMSE: 1.029522892082266\n",
      "Epoch: 1059000000 RMSE: 1.0295161265333497\n",
      "Epoch: 1060000000 RMSE: 1.0294911420097088\n",
      "Epoch: 1061000000 RMSE: 1.0294989695939174\n",
      "Epoch: 1062000000 RMSE: 1.0294962709513378\n",
      "Epoch: 1063000000 RMSE: 1.0294761425087666\n",
      "Epoch: 1064000000 RMSE: 1.0294584959179918\n",
      "Epoch: 1065000000 RMSE: 1.0294625553616759\n",
      "Epoch: 1066000000 RMSE: 1.0294559065645843\n",
      "Epoch: 1067000000 RMSE: 1.0294316221125916\n",
      "Epoch: 1068000000 RMSE: 1.0294425997269414\n",
      "Epoch: 1069000000 RMSE: 1.0294432328040148\n",
      "Epoch: 1070000000 RMSE: 1.0294450630702834\n",
      "Epoch: 1071000000 RMSE: 1.0294297320437173\n",
      "Epoch: 1072000000 RMSE: 1.0294106498296443\n",
      "Epoch: 1073000000 RMSE: 1.0293913622759858\n",
      "Epoch: 1074000000 RMSE: 1.0293845509149706\n",
      "Epoch: 1075000000 RMSE: 1.0293798225494597\n",
      "Epoch: 1076000000 RMSE: 1.0293555035098836\n",
      "Epoch: 1077000000 RMSE: 1.0293410766429036\n",
      "Epoch: 1078000000 RMSE: 1.0293447571644363\n",
      "Epoch: 1079000000 RMSE: 1.0293337494195454\n",
      "Epoch: 1080000000 RMSE: 1.029329004408576\n",
      "Epoch: 1081000000 RMSE: 1.0293239487019552\n",
      "Epoch: 1082000000 RMSE: 1.0293031419621945\n",
      "Epoch: 1083000000 RMSE: 1.02931030608623\n",
      "Epoch: 1084000000 RMSE: 1.0292852107598287\n",
      "Epoch: 1085000000 RMSE: 1.0292656673667184\n",
      "Epoch: 1086000000 RMSE: 1.0292436981964104\n",
      "Epoch: 1087000000 RMSE: 1.0292461922173222\n",
      "Epoch: 1088000000 RMSE: 1.029235448060892\n",
      "Epoch: 1089000000 RMSE: 1.0292188610683162\n",
      "Epoch: 1090000000 RMSE: 1.0292034523232414\n",
      "Epoch: 1091000000 RMSE: 1.0292071374308767\n",
      "Epoch: 1092000000 RMSE: 1.0292077761344134\n",
      "Epoch: 1093000000 RMSE: 1.0291998591005431\n",
      "Epoch: 1094000000 RMSE: 1.029213518517116\n",
      "Epoch: 1095000000 RMSE: 1.0292099987282086\n",
      "Epoch: 1096000000 RMSE: 1.0291945146286465\n",
      "Epoch: 1097000000 RMSE: 1.0291650745778562\n",
      "Epoch: 1098000000 RMSE: 1.0291514543424662\n",
      "Epoch: 1099000000 RMSE: 1.029150963692984\n",
      "Epoch: 1100000000 RMSE: 1.0291524096205726\n",
      "Epoch: 1101000000 RMSE: 1.029140591621555\n",
      "Epoch: 1102000000 RMSE: 1.0291335199800062\n",
      "Epoch: 1103000000 RMSE: 1.0291253368100393\n",
      "Epoch: 1104000000 RMSE: 1.0291163114498527\n",
      "Epoch: 1105000000 RMSE: 1.0291202200612637\n",
      "Epoch: 1106000000 RMSE: 1.0291240632203758\n",
      "Epoch: 1107000000 RMSE: 1.0291187762896874\n",
      "Epoch: 1108000000 RMSE: 1.0291253829329308\n",
      "Epoch: 1109000000 RMSE: 1.0291283963045401\n",
      "Epoch: 1110000000 RMSE: 1.0291295359743184\n",
      "Epoch: 1111000000 RMSE: 1.0291317568441753\n",
      "Epoch: 1112000000 RMSE: 1.0291348361601467\n",
      "Epoch: 1113000000 RMSE: 1.0291291696420406\n",
      "Epoch: 1114000000 RMSE: 1.0291150340691637\n",
      "Epoch: 1115000000 RMSE: 1.0291084386306195\n",
      "Epoch: 1116000000 RMSE: 1.029106938878749\n",
      "Epoch: 1117000000 RMSE: 1.029104821299413\n",
      "Epoch: 1118000000 RMSE: 1.0290997118258824\n",
      "Epoch: 1119000000 RMSE: 1.0291138215808702\n",
      "Epoch: 1120000000 RMSE: 1.0290946774698886\n",
      "Epoch: 1121000000 RMSE: 1.0290770509713196\n",
      "Epoch: 1122000000 RMSE: 1.0290808995424734\n",
      "Epoch: 1123000000 RMSE: 1.0290835531041593\n",
      "Epoch: 1124000000 RMSE: 1.0290797641794782\n",
      "Epoch: 1125000000 RMSE: 1.029069479130288\n",
      "Epoch: 1126000000 RMSE: 1.0290764006507909\n",
      "Epoch: 1127000000 RMSE: 1.0290837433722686\n",
      "Epoch: 1128000000 RMSE: 1.02908097407915\n",
      "Epoch: 1129000000 RMSE: 1.029074328786271\n",
      "Epoch: 1130000000 RMSE: 1.0290794292672099\n",
      "Epoch: 1131000000 RMSE: 1.0290733468458448\n",
      "Epoch: 1132000000 RMSE: 1.0290491548511815\n",
      "Epoch: 1133000000 RMSE: 1.0290400628228005\n",
      "Epoch: 1134000000 RMSE: 1.0290247403917954\n",
      "Epoch: 1135000000 RMSE: 1.0290152771707939\n",
      "Epoch: 1136000000 RMSE: 1.0290022966892196\n",
      "Epoch: 1137000000 RMSE: 1.0290039302291825\n",
      "Epoch: 1138000000 RMSE: 1.0290048028780165\n",
      "Epoch: 1139000000 RMSE: 1.0289938102086413\n",
      "Epoch: 1140000000 RMSE: 1.029000148990014\n",
      "Epoch: 1141000000 RMSE: 1.0289897799190928\n",
      "Epoch: 1142000000 RMSE: 1.0289886601870728\n",
      "Epoch: 1143000000 RMSE: 1.0289878258233922\n",
      "Epoch: 1144000000 RMSE: 1.028976515414314\n",
      "Epoch: 1145000000 RMSE: 1.0289843939827055\n",
      "Epoch: 1146000000 RMSE: 1.0289553466875287\n",
      "Epoch: 1147000000 RMSE: 1.028940636444769\n",
      "Epoch: 1148000000 RMSE: 1.0289410848829321\n",
      "Epoch: 1149000000 RMSE: 1.0289112966766671\n",
      "Epoch: 1150000000 RMSE: 1.0288994187301492\n",
      "Epoch: 1151000000 RMSE: 1.0288959482676354\n",
      "Epoch: 1152000000 RMSE: 1.0288820333070325\n",
      "Epoch: 1153000000 RMSE: 1.0288923926566897\n",
      "Epoch: 1154000000 RMSE: 1.028888787777695\n",
      "Epoch: 1155000000 RMSE: 1.028891972593922\n",
      "Epoch: 1156000000 RMSE: 1.028885526297235\n",
      "Epoch: 1157000000 RMSE: 1.0288887497006618\n",
      "Epoch: 1158000000 RMSE: 1.0288621351939622\n",
      "Epoch: 1159000000 RMSE: 1.0288503415194132\n",
      "Epoch: 1160000000 RMSE: 1.0288431297965996\n",
      "Epoch: 1161000000 RMSE: 1.028859631192683\n",
      "Epoch: 1162000000 RMSE: 1.0288466058927683\n",
      "Epoch: 1163000000 RMSE: 1.028850278491354\n",
      "Epoch: 1164000000 RMSE: 1.0288489342272786\n",
      "Epoch: 1165000000 RMSE: 1.0288506612952928\n",
      "Epoch: 1166000000 RMSE: 1.0288464802471828\n",
      "Epoch: 1167000000 RMSE: 1.028826195252436\n",
      "Epoch: 1168000000 RMSE: 1.0288242667950926\n",
      "Epoch: 1169000000 RMSE: 1.0288145675996128\n",
      "Epoch: 1170000000 RMSE: 1.0287999297981694\n",
      "Epoch: 1171000000 RMSE: 1.0287991202887208\n",
      "Epoch: 1172000000 RMSE: 1.0287923624822102\n",
      "Epoch: 1173000000 RMSE: 1.0287751770403732\n",
      "Epoch: 1174000000 RMSE: 1.0287667582599969\n",
      "Epoch: 1175000000 RMSE: 1.0287655324917668\n",
      "Epoch: 1176000000 RMSE: 1.028776425272831\n",
      "Epoch: 1177000000 RMSE: 1.0287686285120974\n",
      "Epoch: 1178000000 RMSE: 1.0287424359779291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1179000000 RMSE: 1.028725522514689\n",
      "Epoch: 1180000000 RMSE: 1.028737642068654\n",
      "Epoch: 1181000000 RMSE: 1.0287172439812151\n",
      "Epoch: 1182000000 RMSE: 1.0286995458235362\n",
      "Epoch: 1183000000 RMSE: 1.0286932960328605\n",
      "Epoch: 1184000000 RMSE: 1.0286917064051109\n",
      "Epoch: 1185000000 RMSE: 1.028670248225917\n",
      "Epoch: 1186000000 RMSE: 1.0286695597658206\n",
      "Epoch: 1187000000 RMSE: 1.0286519113846722\n",
      "Epoch: 1188000000 RMSE: 1.0286327957276833\n",
      "Epoch: 1189000000 RMSE: 1.0286290157290605\n",
      "Epoch: 1190000000 RMSE: 1.028621761578239\n",
      "Epoch: 1191000000 RMSE: 1.0286156694032693\n",
      "Epoch: 1192000000 RMSE: 1.0286252118535748\n",
      "Epoch: 1193000000 RMSE: 1.0286124152219092\n",
      "Epoch: 1194000000 RMSE: 1.0286051342566296\n",
      "Epoch: 1195000000 RMSE: 1.028620777205536\n",
      "Epoch: 1196000000 RMSE: 1.0286042747506288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-127d9064bba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrand_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrated_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrand_j_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrated_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mrand_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrated_movies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_j_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrand_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), np.NaN)\n",
    "mask = np.zeros((number_of_users, number_of_movies))\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "k = 96\n",
    "lmbd = 0.02\n",
    "lr = 0.001\n",
    "\n",
    "epochs = 10000000000\n",
    "U = np.random.normal(loc=0.2, scale=0.2, size=(number_of_users, k))\n",
    "V = np.random.normal(loc=0.2, scale=0.2, size=(k, number_of_movies))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 1000000 == 0:\n",
    "        reconstructed_matrix = U.dot(V)\n",
    "        test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "        test_predictions = np.clip(test_predictions, 1, 5)\n",
    "        print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")    \n",
    "\n",
    "    rand_i = np.random.randint(low=0, high=data.shape[0])\n",
    "    rated_movies = np.argwhere(mask[rand_i, :] == 1).ravel()\n",
    "    rand_j_idx = np.random.randint(low=0, high=len(rated_movies))\n",
    "    rand_j = rated_movies[rand_j_idx]\n",
    "    rand_k = np.random.randint(low=0, high=k)\n",
    "    yijhat = U[rand_i, :].reshape(1, -1).dot(V[:, rand_j].reshape(-1, 1))\n",
    "    yij = data[rand_i, rand_j]\n",
    "    rij = yij - yijhat\n",
    "    U[rand_i, rand_k] += lr * (rij * V[rand_k, rand_j] - lmbd * U[rand_i, rand_k])\n",
    "    V[rand_k, rand_j] += lr * (rij * U[rand_i, rand_k] - lmbd * V[rand_k, rand_j])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:18<00:00, 72.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9984378057749016\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), np.NaN)\n",
    "mask = np.zeros((number_of_users, number_of_movies))\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "user_predictors = []\n",
    "for i in range(data.shape[0]):\n",
    "    current_user_data = data[i, :].ravel()\n",
    "    emp_prob_1 = current_user_data[current_user_data == 1].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_2 = current_user_data[current_user_data == 2].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_3 = current_user_data[current_user_data == 3].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_4 = current_user_data[current_user_data == 4].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_5 = current_user_data[current_user_data == 5].shape[0] / current_user_data.shape[0]\n",
    "    user_predictors.append([emp_prob_1, emp_prob_2, emp_prob_3, emp_prob_4, emp_prob_5])\n",
    "user_predictors = np.array(user_predictors)\n",
    "\n",
    "data_normalized = data - np.nanmean(data, axis=1).reshape(-1, 1)\n",
    "movie_predictors = []\n",
    "for j in range(data_normalized.shape[1]):\n",
    "    current_movie_data = data_normalized[:, j].ravel()\n",
    "    movie_predictors.append(np.nanmean(current_movie_data))\n",
    "movie_predictors = np.array(movie_predictors)\n",
    "\n",
    "lr_train_data = []\n",
    "lr_test_data = []\n",
    "lr_test_data_row_indices = []\n",
    "lr_test_data_col_indices = []\n",
    "for i in tqdm(list(range(user_predictors.shape[0]))):\n",
    "    for j in range(movie_predictors.shape[0]):\n",
    "        if np.isnan(data[i, j]):\n",
    "            lr_test_data.append(np.hstack((user_predictors[i, :], movie_predictors[j])))\n",
    "            lr_test_data_row_indices.append(i)\n",
    "            lr_test_data_col_indices.append(j)\n",
    "        else:\n",
    "            lr_train_data.append(np.hstack((user_predictors[i, :], movie_predictors[j], data[i, j])))\n",
    "lr_train_data = np.array(lr_train_data)\n",
    "lr_test_data = np.array(lr_test_data)\n",
    "lr_test_data_row_indices = np.array(lr_test_data_row_indices)\n",
    "lr_test_data_col_indices = np.array(lr_test_data_col_indices)\n",
    "\n",
    "train_X = lr_train_data[:, :6]\n",
    "train_y = lr_train_data[:, 6].ravel()\n",
    "test_X = lr_test_data\n",
    "model = LGBMRegressor()\n",
    "model.fit(train_X, train_y)\n",
    "predictions = np.clip(model.predict(test_X), 1, 5)\n",
    "reconstructed_matrix = csr_matrix((predictions, (lr_test_data_row_indices, lr_test_data_col_indices))).toarray()\n",
    "test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "print(f\"RMSE: {get_score(test_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC + RSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:20<00:00, 71.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "# from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), np.NaN)\n",
    "mask = np.zeros((number_of_users, number_of_movies))\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "user_predictors = []\n",
    "for i in range(data.shape[0]):\n",
    "    current_user_data = data[i, :].ravel()\n",
    "    emp_prob_1 = current_user_data[current_user_data == 1].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_2 = current_user_data[current_user_data == 2].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_3 = current_user_data[current_user_data == 3].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_4 = current_user_data[current_user_data == 4].shape[0] / current_user_data.shape[0]\n",
    "    emp_prob_5 = current_user_data[current_user_data == 5].shape[0] / current_user_data.shape[0]\n",
    "    user_predictors.append([emp_prob_1, emp_prob_2, emp_prob_3, emp_prob_4, emp_prob_5])\n",
    "user_predictors = np.array(user_predictors)\n",
    "\n",
    "data_normalized = data - np.nanmean(data, axis=1).reshape(-1, 1)\n",
    "movie_predictors = []\n",
    "for j in range(data_normalized.shape[1]):\n",
    "    current_movie_data = data_normalized[:, j].ravel()\n",
    "    movie_predictors.append(np.nanmean(current_movie_data))\n",
    "movie_predictors = np.array(movie_predictors)\n",
    "\n",
    "lr_train_data = []\n",
    "lr_test_data = []\n",
    "lr_test_data_row_indices = []\n",
    "lr_test_data_col_indices = []\n",
    "for i in tqdm(list(range(user_predictors.shape[0]))):\n",
    "    for j in range(movie_predictors.shape[0]):\n",
    "        lr_test_data.append(np.hstack((user_predictors[i, :], movie_predictors[j])))\n",
    "        lr_test_data_row_indices.append(i)\n",
    "        lr_test_data_col_indices.append(j)\n",
    "        if np.isnan(data[i, j]):\n",
    "            continue\n",
    "        else:\n",
    "            lr_train_data.append(np.hstack((user_predictors[i, :], movie_predictors[j], data[i, j])))\n",
    "lr_train_data = np.array(lr_train_data)\n",
    "lr_test_data = np.array(lr_test_data)\n",
    "lr_test_data_row_indices = np.array(lr_test_data_row_indices)\n",
    "lr_test_data_col_indices = np.array(lr_test_data_col_indices)\n",
    "\n",
    "train_X = lr_train_data[:, :6]\n",
    "train_y = lr_train_data[:, 6].ravel()\n",
    "test_X = lr_test_data\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "predictions = np.clip(model.predict(test_X), 1, 5)\n",
    "reconstructed_matrix_basic = csr_matrix((predictions, (lr_test_data_row_indices, lr_test_data_col_indices))).toarray()\n",
    "\n",
    "data = data - reconstructed_matrix_basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 RMSE: 1.0016646979512493\n",
      "Epoch: 1000000 RMSE: 1.001660772679242\n",
      "Epoch: 2000000 RMSE: 1.001657510204613\n",
      "Epoch: 3000000 RMSE: 1.0016550975247087\n",
      "Epoch: 4000000 RMSE: 1.0016513752078418\n",
      "Epoch: 5000000 RMSE: 1.001644717729854\n",
      "Epoch: 6000000 RMSE: 1.0016436077660102\n",
      "Epoch: 7000000 RMSE: 1.0016390980373366\n",
      "Epoch: 8000000 RMSE: 1.0016360349631084\n",
      "Epoch: 9000000 RMSE: 1.0016347545944624\n",
      "Epoch: 10000000 RMSE: 1.0016284523885832\n",
      "Epoch: 11000000 RMSE: 1.0016254864414382\n",
      "Epoch: 12000000 RMSE: 1.001621566718368\n",
      "Epoch: 13000000 RMSE: 1.0016194651508352\n",
      "Epoch: 14000000 RMSE: 1.0016144903435515\n",
      "Epoch: 15000000 RMSE: 1.00160739836946\n",
      "Epoch: 16000000 RMSE: 1.001604569436229\n",
      "Epoch: 17000000 RMSE: 1.0015992345117406\n",
      "Epoch: 18000000 RMSE: 1.0015967753921802\n",
      "Epoch: 19000000 RMSE: 1.0015923996532574\n",
      "Epoch: 20000000 RMSE: 1.0015933174409148\n",
      "Epoch: 21000000 RMSE: 1.0015873134198112\n",
      "Epoch: 22000000 RMSE: 1.0015824355741512\n",
      "Epoch: 23000000 RMSE: 1.0015783186574834\n",
      "Epoch: 24000000 RMSE: 1.001576228376824\n",
      "Epoch: 25000000 RMSE: 1.0015716808116641\n",
      "Epoch: 26000000 RMSE: 1.00156747958834\n",
      "Epoch: 27000000 RMSE: 1.0015610615774126\n",
      "Epoch: 28000000 RMSE: 1.0015579640020855\n",
      "Epoch: 29000000 RMSE: 1.0015559946252697\n",
      "Epoch: 30000000 RMSE: 1.0015505656507806\n",
      "Epoch: 31000000 RMSE: 1.0015462880334904\n",
      "Epoch: 32000000 RMSE: 1.001545937652775\n",
      "Epoch: 33000000 RMSE: 1.0015420854427044\n",
      "Epoch: 34000000 RMSE: 1.0015402448637156\n",
      "Epoch: 35000000 RMSE: 1.0015358142977662\n",
      "Epoch: 36000000 RMSE: 1.0015307676650138\n",
      "Epoch: 37000000 RMSE: 1.0015261985959654\n",
      "Epoch: 38000000 RMSE: 1.001520799070281\n",
      "Epoch: 39000000 RMSE: 1.001520128774791\n",
      "Epoch: 40000000 RMSE: 1.0015117447574968\n",
      "Epoch: 41000000 RMSE: 1.0015051697414863\n",
      "Epoch: 42000000 RMSE: 1.0015020366564402\n",
      "Epoch: 43000000 RMSE: 1.0014986315213419\n",
      "Epoch: 44000000 RMSE: 1.0014940478504768\n",
      "Epoch: 45000000 RMSE: 1.001490441091555\n",
      "Epoch: 46000000 RMSE: 1.0014887662524352\n",
      "Epoch: 47000000 RMSE: 1.0014817940759533\n",
      "Epoch: 48000000 RMSE: 1.0014819633528738\n",
      "Epoch: 49000000 RMSE: 1.0014785990302868\n",
      "Epoch: 50000000 RMSE: 1.0014748802438427\n",
      "Epoch: 51000000 RMSE: 1.0014700127535614\n",
      "Epoch: 52000000 RMSE: 1.0014687407126386\n",
      "Epoch: 53000000 RMSE: 1.0014649060738727\n",
      "Epoch: 54000000 RMSE: 1.0014603703360636\n",
      "Epoch: 55000000 RMSE: 1.0014582143088846\n",
      "Epoch: 56000000 RMSE: 1.0014570630652042\n",
      "Epoch: 57000000 RMSE: 1.0014548482638692\n",
      "Epoch: 58000000 RMSE: 1.0014500583772912\n",
      "Epoch: 59000000 RMSE: 1.0014501637620996\n",
      "Epoch: 60000000 RMSE: 1.0014439897222414\n",
      "Epoch: 61000000 RMSE: 1.0014409107907363\n",
      "Epoch: 62000000 RMSE: 1.001437764729189\n",
      "Epoch: 63000000 RMSE: 1.0014313196004887\n",
      "Epoch: 64000000 RMSE: 1.001426238830261\n",
      "Epoch: 65000000 RMSE: 1.001421442481837\n",
      "Epoch: 66000000 RMSE: 1.001420647716041\n",
      "Epoch: 67000000 RMSE: 1.0014142708453666\n",
      "Epoch: 68000000 RMSE: 1.0014114024679888\n",
      "Epoch: 69000000 RMSE: 1.001406698591766\n",
      "Epoch: 70000000 RMSE: 1.001402800117867\n",
      "Epoch: 71000000 RMSE: 1.0013981971664807\n",
      "Epoch: 72000000 RMSE: 1.0013950796588391\n",
      "Epoch: 73000000 RMSE: 1.0013916904973337\n",
      "Epoch: 74000000 RMSE: 1.0013887330491278\n",
      "Epoch: 75000000 RMSE: 1.001384959667091\n",
      "Epoch: 76000000 RMSE: 1.0013793185501374\n",
      "Epoch: 77000000 RMSE: 1.0013749643163754\n",
      "Epoch: 78000000 RMSE: 1.0013704239657355\n",
      "Epoch: 79000000 RMSE: 1.0013688561396314\n",
      "Epoch: 80000000 RMSE: 1.0013678269193012\n",
      "Epoch: 81000000 RMSE: 1.0013665195516228\n",
      "Epoch: 82000000 RMSE: 1.0013633106382809\n",
      "Epoch: 83000000 RMSE: 1.0013585323405176\n",
      "Epoch: 84000000 RMSE: 1.0013540367128742\n",
      "Epoch: 85000000 RMSE: 1.0013500994873896\n",
      "Epoch: 86000000 RMSE: 1.00134559519457\n",
      "Epoch: 87000000 RMSE: 1.0013427794103211\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-b1358b240261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrand_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mrated_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mrand_j_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrated_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mrand_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrated_movies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_j_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100000000\n",
    "lr = 0.001\n",
    "lmbd = 0.02\n",
    "k = 96\n",
    "\n",
    "data[mask == 0] = 0\n",
    "U, s, V = np.linalg.svd(data)\n",
    "U = U[:, :96]\n",
    "s = s[:96]\n",
    "V = V[:96, :]\n",
    "S = np.diag(s)\n",
    "U = U.dot(np.sqrt(S))\n",
    "V = np.sqrt(S).dot(V)\n",
    "\n",
    "# U = np.random.normal(loc=0.2, scale=0.2, size=(number_of_users, k))\n",
    "# V = np.random.normal(loc=0.2, scale=0.2, size=(k, number_of_movies))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 1000000 == 0:\n",
    "        reconstructed_matrix_rsvd = U.dot(V)\n",
    "        test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix_rsvd + reconstructed_matrix_basic)\n",
    "        test_predictions = np.clip(test_predictions, 1, 5)\n",
    "        print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")    \n",
    "\n",
    "    rand_i = np.random.randint(low=0, high=data.shape[0])\n",
    "    rated_movies = np.argwhere(mask[rand_i, :] == 1).ravel()\n",
    "    rand_j_idx = np.random.randint(low=0, high=len(rated_movies))\n",
    "    rand_j = rated_movies[rand_j_idx]\n",
    "    rand_k = np.random.randint(low=0, high=k)\n",
    "    yijhat = U[rand_i, :].reshape(1, -1).dot(V[:, rand_j].reshape(-1, 1))\n",
    "    yij = data[rand_i, rand_j]\n",
    "    rij = yij - yijhat\n",
    "    U[rand_i, rand_k] += lr * (rij * V[rand_k, rand_j] - lmbd * U[rand_i, rand_k])\n",
    "    V[rand_k, rand_j] += lr * (rij * U[rand_i, rand_k] - lmbd * V[rand_k, rand_j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTU1gc-bPOm-"
   },
   "source": [
    "## Improved SVD\n",
    " \n",
    "Can we also include user-specific or movie-specific biases?\n",
    " \n",
    "Compare to the simple SVD assumption\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} =  p_u^T q_i,\n",
    "\\end{equation}\n",
    "a more reasonable premise is [1]\n",
    "\\begin{equation}\n",
    "r_{ui} = p_u^T q_i + b_u + b_i,\n",
    "\\end{equation}\n",
    "where $b_u, b_i \\in \\mathbb{R}$, allowing to model a significant portion of the observed variation that comes from effects associated with either the user or the items.\n",
    " \n",
    "This allows us to model more complex interactions. Optimization is done similarly to (ALS).\n",
    " \n",
    "------------\n",
    "[1] Paterek, Arkadiusz. \"Improving regularized singular value decomposition for collaborative filtering.\" Proceedings of KDD cup and workshop. Vol. 2007. 2007.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 196/10000 [00:00<00:09, 989.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 RMSE: 3.2729175234325862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 822.35it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 94.35it/s]\n",
      "  1%|          | 103/10000 [00:00<00:09, 1020.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 RMSE: 1.014393820484168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 961.87it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 96.27it/s]\n",
      "  2%|▏         | 195/10000 [00:00<00:10, 976.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 RMSE: 1.0081646297045919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 979.49it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 103.60it/s]\n",
      "  1%|          | 100/10000 [00:00<00:09, 998.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 RMSE: 1.0081027926928607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 959.43it/s]\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 95.50it/s]\n",
      "  1%|          | 104/10000 [00:00<00:09, 1036.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 RMSE: 1.0081001121775193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1045.04it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 100.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n",
    "\n",
    "data = np.full((number_of_users, number_of_movies), 0)\n",
    "mask = np.zeros((number_of_users, number_of_movies))\n",
    "\n",
    "for user, movie, pred in zip(train_users, train_movies, train_predictions):\n",
    "    data[user][movie] = pred\n",
    "    mask[user][movie] = 1\n",
    "\n",
    "k = 10\n",
    "lmbd = 0.2\n",
    "lr = 0.5\n",
    "\n",
    "epochs = 5\n",
    "U = np.random.normal(loc=0.2, scale=0.2, size=(number_of_users, k))\n",
    "V = np.random.normal(loc=0.2, scale=0.2, size=(k, number_of_movies))\n",
    "bu = np.random.normal(loc=0.2, scale=0.2, size=(number_of_users, 1))\n",
    "bv = np.random.normal(loc=0.2, scale=0.2, size=(number_of_movies, 1))\n",
    "\n",
    "# without sgd\n",
    "for epoch in range(epochs):\n",
    "    reconstructed_matrix = U.dot(V) + bu + bv.T\n",
    "    test_predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "    print(f\"Epoch: {epoch} RMSE: {get_score(test_predictions)}\")\n",
    "    \n",
    "    for i in tqdm(list(range(number_of_users))):\n",
    "        rated_movie_indices = np.argwhere(mask[i, :] == 1).ravel()\n",
    "        bu_update = 0\n",
    "        ui = U[i, :].reshape(-1, 1)\n",
    "        for j in rated_movie_indices:\n",
    "            vj = V[:, j].reshape(-1, 1)\n",
    "            bu_update += data[i, j] - vj.T.dot(ui) - bv[j, 0]\n",
    "        bu[i, :] = bu_update / len(rated_movie_indices)\n",
    "    \n",
    "    for j in tqdm(list(range(number_of_movies))):\n",
    "        rater_user_indices = np.argwhere(mask[:, j] == 1).ravel()\n",
    "        bv_update = 0\n",
    "        vj = V[:, j].reshape(-1, 1)\n",
    "        for i in rater_user_indices:\n",
    "            ui = U[i, :].reshape(-1, 1)\n",
    "            bv_update += data[i, j] - ui.T.dot(vj) - bu[i, 0]\n",
    "        bv[j, :] = bv_update / len(rater_user_indices)\n",
    "    \n",
    "#     for i in tqdm(list(range(number_of_users))):\n",
    "#         rated_movie_indices = np.argwhere(mask[i, :] == 1).ravel()\n",
    "#         ui = U[i, :].reshape(-1, 1)\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for j in rated_movie_indices:\n",
    "#             vj = V[:, j].reshape(-1, 1)\n",
    "#             left += vj.dot(vj.T)\n",
    "#             right += (data[i, j] - bu[i, 0] - bv[j, 0]) * vj\n",
    "#         U[i, :] = np.linalg.inv(left).dot(right).ravel()\n",
    "# \n",
    "#     for j in tqdm(list(range(number_of_movies))):\n",
    "#         rater_user_indices = np.argwhere(mask[:, j] == 1).ravel()\n",
    "#         vj = V[:, j].reshape(-1, 1)\n",
    "#         left = lmbd * np.eye(k)\n",
    "#         right = np.zeros((k, 1))\n",
    "#         for i in rater_user_indices:\n",
    "#             ui = U[i, :].reshape(-1, 1)\n",
    "#             left += ui.dot(ui.T)\n",
    "#             right += (data[i, j] - bu[i, 0] - bv[j, 0]) * ui \n",
    "#         V[:, j] = np.linalg.inv(left).dot(right).ravel()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIAxK7xEDSBx"
   },
   "source": [
    "Exercise:\n",
    "- Implement ALS and Improved SVD and test its performance on the test dataset. Especially for large datasets, optimization via [Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) is chosen (more on this in later lectures). Derive the derivatives in terms of $p_u, q_i, b_u, b_i$ and choose a suitable learning rate (a specific value or decaying with time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1Ln7-UYOc3B"
   },
   "source": [
    "## Autoencoder\n",
    "An autoencoder is a type of neural network that is used to learn efficient, low-dimensional data representations in an unsupervised manner [1]. It implements two transformations: first, the encoder $g_e : \\mathbb{R}^d \\rightarrow \\mathbb{R}^k$ and secondly, the decoder $g_d : \\mathbb{R}^k \\rightarrow \\mathbb{R}^d$, where $k < d$. The network is trained by minimizing the squared reconstruction loss between the input $ x$ and output $\\hat{x} = g_d(g_e(x))$, thereafter learning an intermediate $k-$dimensional representation for $x$.\n",
    "\n",
    "----------\n",
    "\n",
    "[1] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \"Reducing the dimensionality of data with neural networks.\" science 313.5786 (2006): 504-507.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE4JPRN0VPlo"
   },
   "source": [
    "![autoencode.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9MRZnXVVR9o"
   },
   "source": [
    "Similar to the SVD assumptions we may choose to use an autoencoder to learn the interactions. Deep autoencoders allow capruting of non-linear more complex interconnections. Autoencoders have proven to be very effective in the context of collaborative filtering [1, 2, 3]. Reconstruct for each user their \n",
    "\n",
    "------------\n",
    "[1] Sedhain, Suvash, et al. \"Autorec: Autoencoders meet collaborative filtering.\" Proceedings of the 24th international conference on World Wide Web. 2015.\n",
    "\n",
    "[2] Strub, Florian, and Jeremie Mary. \"Collaborative filtering with stacked denoising autoencoders and sparse inputs.\" NIPS workshop on machine learning for eCommerce. 2015.\n",
    "\n",
    "[3] Kuchaiev, Oleksii, and Boris Ginsburg. \"Training deep autoencoders for collaborative filtering.\" arXiv preprint arXiv:1708.01715 (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4_7Z9KuMXYM1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#@title Use GPU in colab: Runtime->Change Runtime type\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNfSDd5AVmiq"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dimension, encoded_dimension=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=input_dimension, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=encoded_dimension),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dimensions, encoded_dimension=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=encoded_dimension, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=output_dimensions),\n",
    "            nn.ReLU() # How does the output look like? What about if you had first centered the data?!\n",
    "        )\n",
    "    \n",
    "    def forward(self, encodings):\n",
    "        return self.model(encodings)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.decoder(self.encoder(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfwrZJd9bTYn"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "show_validation_score_every_epochs = 5\n",
    "encoded_dimension = 16\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNORXo2cbFRD"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "autoencoder = AutoEncoder(\n",
    "    encoder=Encoder(\n",
    "        input_dimension=number_of_movies,\n",
    "        encoded_dimension=encoded_dimension,\n",
    "    ),\n",
    "    decoder=Decoder(\n",
    "        output_dimensions=number_of_movies,\n",
    "        encoded_dimension=encoded_dimension,\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(autoencoder.parameters(),\n",
    "                       lr=learning_rate)\n",
    "\n",
    "# Build Dataloaders\n",
    "data_torch = torch.tensor(data, device=device).float()\n",
    "mask_torch = torch.tensor(mask, device=device)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    TensorDataset(data_torch, mask_torch),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# L2 loss between original ratings and reconstructed ratings for the observed values\n",
    "def loss_function(original, reconstructed, mask):\n",
    "    return torch.mean(mask * (original - reconstructed) ** 2)\n",
    "\n",
    "# reconstuct the whole array\n",
    "def reconstruct_whole_matrix(autoencoder):\n",
    "    data_reconstructed = np.zeros((number_of_users, number_of_movies))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, number_of_users, batch_size):\n",
    "            upper_bound = min(i + batch_size, number_of_users)\n",
    "            data_reconstructed[i:upper_bound] = autoencoder(data_torch[i:upper_bound]).detach().cpu().numpy()\n",
    "\n",
    "    return data_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyjbVFodbuE9"
   },
   "outputs": [],
   "source": [
    "# collect losses for qualitative inspection\n",
    "autoencoder_logdir = './tensorboard/autoencoder'\n",
    "writer = SummaryWriter(autoencoder_logdir)\n",
    "\n",
    "step = 0\n",
    "with tqdm(total=len(dataloader) * num_epochs) as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        for data_batch, mask_batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            reconstructed_batch = autoencoder(data_batch)\n",
    "\n",
    "            loss = loss_function(data_batch, reconstructed_batch, mask_batch)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar('loss', loss, step)\n",
    "            pbar.update(1)\n",
    "            step += 1\n",
    "\n",
    "        if epoch % show_validation_score_every_epochs == 0:\n",
    "            reconstructed_matrix = reconstruct_whole_matrix(autoencoder)\n",
    "            predictions = extract_prediction_from_full_matrix(reconstructed_matrix)\n",
    "            reconstuction_rmse = get_score(predictions)\n",
    "            pbar.set_description('At epoch {:3d} loss is {:.4f}'.format(epoch, reconstuction_rmse))\n",
    "\n",
    "            writer.add_scalar('reconstuction_rmse', reconstuction_rmse, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-mtyVLAbuJC"
   },
   "outputs": [],
   "source": [
    "# We can visualize the tensorboard logs.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_tq-uGgVl6o"
   },
   "source": [
    "What modifications can be made to make our autoencoder model much better?\n",
    "* Are the layer's parameters optimal?\n",
    "* Can we introduce regularization for the autoencoder as well?\n",
    "* Can we add user biases, similar to improved SVD?\n",
    "* Here we have encoded users, can we do the same with movies?\n",
    "* Extensions to [autoencoders](https://en.wikipedia.org/wiki/Autoencoder) include variational autoencoders.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts01dtvCZsNZ"
   },
   "source": [
    "## Neural Collaborative Filtering [1]\n",
    "\n",
    "Since artificial neural networks have good capabilities to approximate any function [2, 3] we adopt the Neural Collaborative Filtering approach proposed by [1] to jointly learn both the user-item latent representations as well as the prediction rule of user-item interactions. \n",
    "\n",
    "-----------------\n",
    "\n",
    "[1] He, Xiangnan, et al. \"Neural collaborative filtering.\" Proceedings of the 26th international conference on world wide web. 2017\n",
    "\n",
    "[2] Cybenko, George. \"Approximation by superpositions of a sigmoidal function.\" Mathematics of control, signals and systems 2.4 (1989): 303-314.\n",
    "\n",
    "[3] Hornik, Kurt, Maxwell Stinchcombe, and Halbert White. \"Multilayer feedforward networks are universal approximators.\" Neural networks 2.5 (1989): 359-366."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK8vnPDaXEBJ"
   },
   "source": [
    "![Screenshot from 2021-03-06 12-46-14.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cr31qDI1XPOT"
   },
   "source": [
    "We use a simple architecture displayed above. For more details on embedding layers see upcoming lectures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y_X9dwvg3S8D"
   },
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, number_of_users, number_of_movies, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n",
    "        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(in_features=2 * embedding_size, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=1), # maybe predict per category?\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, users, movies):\n",
    "        users_embedding = self.embedding_layer_users(users)\n",
    "        movies_embedding = self.embedding_layer_movies(movies)\n",
    "        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n",
    "        return torch.squeeze(self.feed_forward(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZFEKekJnYD31"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 1024\n",
    "num_epochs = 25\n",
    "show_validation_score_every_epochs = 1\n",
    "embedding_size = 16\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Cw4WY94tZM7B"
   },
   "outputs": [],
   "source": [
    "def mse_loss(predictions, target):\n",
    "    return torch.mean((predictions - target) ** 2)\n",
    "\n",
    "# Build Dataloaders\n",
    "train_users_torch = torch.tensor(train_users, device=device)\n",
    "train_movies_torch = torch.tensor(train_movies, device=device)\n",
    "train_predictions_torch = torch.tensor(train_predictions, device=device)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    TensorDataset(train_users_torch, train_movies_torch, train_predictions_torch),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_users_torch = torch.tensor(test_users, device=device)\n",
    "test_movies_torch = torch.tensor(test_movies, device=device)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TensorDataset(test_users_torch, test_movies_torch),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "ncf = NCF(number_of_users, number_of_movies, embedding_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(ncf.parameters(),\n",
    "                       lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oQa_lfwNZJaJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7647974447744d68d542ef1b95ad0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a36d8ef601d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# writer.add_scalar('loss', loss, step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"retains_grad\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n\u001b[1;32m    920\u001b[0m                           \u001b[0;34m\"attribute won't be populated during autograd.backward(). If you indeed want the gradient \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# collect losses for qualitative inspection\n",
    "ncf_logdir = './tensorboard/ncf'\n",
    "# writer = SummaryWriter(ncf_logdir)\n",
    "\n",
    "step = 0\n",
    "with tqdm(total=len(train_dataloader) * num_epochs) as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        for users_batch, movies_batch, target_predictions_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions_batch = ncf(users_batch, movies_batch)\n",
    "\n",
    "            loss = mse_loss(predictions_batch, target_predictions_batch)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # writer.add_scalar('loss', loss, step)\n",
    "            pbar.update(1)\n",
    "            step += 1\n",
    "\n",
    "        if epoch % show_validation_score_every_epochs == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                all_predictions = []\n",
    "                for users_batch, movies_batch in test_dataloader:\n",
    "                    predictions_batch = ncf(users_batch, movies_batch)\n",
    "                    all_predictions.append(predictions_batch)\n",
    "                \n",
    "            all_predictions = torch.cat(all_predictions)\n",
    "\n",
    "            reconstuction_rmse = get_score(all_predictions.cpu().numpy())\n",
    "            pbar.set_description('At epoch {:3d} loss is {:.4f}'.format(epoch, reconstuction_rmse))\n",
    "\n",
    "            # writer.add_scalar('reconstuction_rmse', reconstuction_rmse, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y97fnE7pfB5v"
   },
   "outputs": [],
   "source": [
    "# We can visualize the tensorboard logs.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9J9Jwy8XZpg"
   },
   "source": [
    "To consider:\n",
    "* Try different layer choices.\n",
    "* Can we also combine different aforementioned ideas in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFEa27vx30__"
   },
   "source": [
    "# Other ideas\n",
    "\n",
    "Other ideas:\n",
    "* Differentiable Inference and Generative Models.\n",
    "* Adapt the loss for the predictions that are the most far off and contribute the most towards the RMSE.\n",
    "* Graph-based approaches.\n",
    "* Neighborhood approaches.\n",
    "* Clustering approaches.\n",
    "* Many more... Be creative!\n",
    "\n",
    "----------\n",
    "\n",
    "[1] Lee, Soojung. \"Improving jaccard index for measuring similarity in collaborative filtering.\" International Conference on Information Science and Applications. Springer, Singapore, 2017.\n",
    "[2] Liu, Haifeng, et al. \"A new user similarity model to improve the accuracy of collaborative filtering.\" Knowledge-Based Systems 56 (2014): 156-166.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0CxJl424tHo"
   },
   "source": [
    "# Getting started with the project\n",
    "\n",
    "### Google Colab:\n",
    "\n",
    "Colaboratory, or \"Colab\" for short, allows you to write and execute Python in your browser, with \n",
    "- Zero configuration required\n",
    "- Free access to GPUs\n",
    "- Easy sharing\n",
    "\n",
    "[Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) to learn more.\n",
    "\n",
    "### ETH clusters\n",
    "\n",
    "ETH provides access to the [Euler](https://scicomp.ethz.ch/wiki/Euler) and [Leonhard](https://scicomp.ethz.ch/wiki/Leonhard) cluster (see also [Getting started with clusters](https://scicomp.ethz.ch/wiki/Getting_started_with_clusters#SSH_keys)).\n",
    "\n",
    "To start:\n",
    "- Open VPN!\n",
    "- [Setup SSH keys](https://scicomp.ethz.ch/wiki/Getting_started_with_clusters#SSH_keys) (only need to do that once).\n",
    "- Can even run jupyter-notebooks via [this](https://scicomp.ethz.ch/wiki/Jupyter_on_Euler_and_Leonhard_Open). If you want to run with a GPU may need to change the file accordingly (line 64: \"python_cpu/3.6.4\" -> \"python_gpu/x.x.x\" see [this](https://scicomp.ethz.ch/wiki/Python_on_Leonhard) for available versions, line 139 to request a GPU change rusage demands). To see tensorboard results you can mount the remote directory\n",
    "```\n",
    "sshfs <ethz-username>@<cluster-hostname>:<directory>\n",
    "```\n",
    "and run tensorboard locally \n",
    "```\n",
    "tensorboard --logdir <directory>\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "collaborative_filtering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
